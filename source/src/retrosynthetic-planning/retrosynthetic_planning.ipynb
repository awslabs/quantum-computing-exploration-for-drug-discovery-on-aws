{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2fe146",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2022.03.5 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# from utility.RetroParser import RetroData\n",
    "from utility.RetroGateModel import RetroRLModel\n",
    "from utility.RetroRLAgent import RetroRLAgent\n",
    "# from utility.ResultProcess import ResultParser\n",
    "from utility.DataPrepare import Prepare\n",
    "from utility.BruteForceSearch import expansion, Product, Reaction\n",
    "import time\n",
    "import numpy as np\n",
    "# # Use Braket SDK Cost Tracking to estimate the cost to run this example\n",
    "# from braket.tracking import Tracker\n",
    "# t = Tracker().start()\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6b938",
   "metadata": {},
   "source": [
    "# Step 1: Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b418f",
   "metadata": {},
   "source": [
    "In this part, we load the retrosynthesis prediction data for experiment.\n",
    "The [USPTO-50K](https://tdcommons.ai/generation_tasks/retrosyn/#uspto-50k) was \n",
    "put in the repository. We assign the relative \n",
    "path to **raw_path**.\n",
    "The **s3_bucket** and **prefix** are used to store the \n",
    "results. We can use the one created with the \n",
    "cloudformation for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24175d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:parse xlsx file!\n",
      "INFO:root:There are at most 4 reactants in one reaction!\n",
      "INFO:root:Start picking dataset.\n",
      "  8%|█████▉                                                                     | 3983/50037 [09:18<1:51:25,  6.89it/s]"
     ]
    }
   ],
   "source": [
    "# input: predata_uspto-50k.xlsx\n",
    "# output: file1.npy,file2.npy\n",
    "raw_path = './uspto50k.xlsx'\n",
    "prepare = Prepare(raw_path)\n",
    "prepare.generate_files()  # \n",
    "prepare.generate_ground_truth()\n",
    "ground_truth = np.load(prepare.path+'ground_truth.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "!mkdir $data_path\n",
    "# !cp buyable.npy $data_path\n",
    "# !cp deadend.npy $data_path\n",
    "# !cp reactions_dictionary.npy $data_path\n",
    "# !cp smiles_dictionary.npy $data_path\n",
    "# !cp target_product.npy $data_path\n",
    "# !cp ground_truth.npy $data_path\n",
    "\n",
    "# windows\n",
    "!copy buyable.npy $data_path\n",
    "!copy deadend.npy $data_path\n",
    "!copy reactions_dictionary.npy $data_path\n",
    "!copy smiles_dictionary.npy $data_path\n",
    "!copy target_product.npy $data_path\n",
    "!copy ground_truth.npy $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431116a",
   "metadata": {},
   "source": [
    "# Step 2: Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f8310",
   "metadata": {},
   "source": [
    "In this part, we build the circuit model for retrosynthetic planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial the RetroRLModel object\n",
    "init_param = {}\n",
    "method = ['retro-rl', 'retro-qrl']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'retro-rl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['inputsize', 'middlesize', 'outputsize']\n",
    "    elif mt == 'retro-qrl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['n_qubits', 'device', 'framework', 'shots']\n",
    "    \n",
    "retro_rl_model = RetroRLModel(data=None, method=method, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea6e07-8dc2-4a44-bb18-285f6b576fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param={}\n",
    "method = 'retro-rl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['inputsize'] = [256]\n",
    "model_param[method]['middlesize'] = [512]\n",
    "model_param[method]['outputsize'] = [1]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param={}\n",
    "method = 'retro-qrl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['n_qubits'] = [8]\n",
    "model_param[method]['device'] = ['local', 'sv1', 'aspen-m2']\n",
    "model_param[method]['framework'] = ['pennylane']\n",
    "model_param[method]['shots'] = [100]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9624b3f",
   "metadata": {},
   "source": [
    "We can use the following method to check the properties of \n",
    "model. This way, we can build many models conveniently. \n",
    "After that, we save the model and update the value of \n",
    "**model_path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the model parameters\n",
    "model_info = retro_rl_model.describe_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_path = retro_rl_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the nn model for RL and saved it as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b54a25-9ef1-4e2c-a591-def2a1322db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp $model_path $data_path\n",
    "\n",
    "# windows\n",
    "!copy $model_path $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42eb0f",
   "metadata": {},
   "source": [
    "# Step 3: Learn Retrosynthetic Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3febaf",
   "metadata": {},
   "source": [
    "In this part, we use cpu to run classical model for retrosynthetic planning \n",
    "and simulators/NISQ devices to run quantum model for retrosysnthetic planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad7abf-cdd6-4629-8bc7-8e3b4054b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'sv1'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba9dfc-ca51-43a1-b7bf-9459f3459402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537e938-942f-4357-92d8-95af3735de99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085067ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f803eb8-3a13-4e6b-87f7-2882d8c3ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e06d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b5708-61f0-4427-863f-a3769faa984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'\n",
    "\n",
    "n_qubits = 8\n",
    "device = 'aspen-m2'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80958946-4527-41f3-9b21-e13c77179a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "inputsize = 256\n",
    "middlesize = 512\n",
    "outputsize = 1\n",
    "\n",
    "model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "method = \"retro-rl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab975431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_rl_model = RetroRLModel.load(model_path)\n",
    "model_info = retro_rl_model.describe_model()\n",
    "retro_model = retro_rl_model.get_model(method, model_name)\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game()\n",
    "retro_rl_agent.save(\"latest\", path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_path = retro_rl_agent.save(\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcba0ff",
   "metadata": {},
   "source": [
    "# Step 4: PostProcess Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"local-instance\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58dad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = 'O=C(NCc1ccc(CO)cc1)c1ccccn1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py379",
   "language": "python",
   "name": "py379"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
