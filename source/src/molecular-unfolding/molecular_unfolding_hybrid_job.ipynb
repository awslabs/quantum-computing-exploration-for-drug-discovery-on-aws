{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0531faa8-9b68-4a7f-833a-b18efbac1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.image_uris import Framework, retrieve_image\n",
    "from braket.jobs.config import InstanceConfig\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6283c75a-3c8b-4a9e-9fd8-709e7d8da56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "c = copy.deepcopy\n",
    "\n",
    "def get_key(single_dict):\n",
    "    for k in single_dict.keys():\n",
    "        return k\n",
    "\n",
    "def parse_params(params_list, hp, hp_list):\n",
    "    params = params_list[0]\n",
    "    k = get_key(params)\n",
    "    ps = params[k]\n",
    "    for p in ps:\n",
    "        hp[k] = p\n",
    "        if len(params_list) == 1:\n",
    "            hp_list.append(c(hp))\n",
    "        else:\n",
    "            parse_params(params_list[1:], hp, hp_list)\n",
    "\n",
    "def get_quantum_device(device_name):\n",
    "    device_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\"\n",
    "    try:\n",
    "        device = AwsDevice.get_devices(names=[device_name])\n",
    "        device_arn = device[0].arn\n",
    "    except Exception as e:\n",
    "        print(f\"fail to get {device_name}: {e}, use sv1 instead\")\n",
    "    return device_arn\n",
    "\n",
    "def upload_data(dir_name, aws_session=AwsSession()):\n",
    "    stream_s3_uri = aws_session.construct_s3_uri(aws_session.default_bucket(), dir_name)\n",
    "    return_path = None\n",
    "    \n",
    "    def _check_upload(file_name, check_list):\n",
    "        file_end = file_name.split('.')[-1]\n",
    "        if file_end in check_list:\n",
    "            path = f\"{stream_s3_uri}/\" + file_name.split('/')[-1]\n",
    "            aws_session.upload_to_s3(file_name, path)\n",
    "            \n",
    "    if os.path.isdir(dir_name):\n",
    "        dir_list = os.listdir(dir_name)\n",
    "        for file_name in dir_list:\n",
    "            _check_upload(os.path.join(dir_name,file_name), ['mol2'])\n",
    "        return_path = stream_s3_uri\n",
    "    else:\n",
    "        _check_upload(file_name, ['mol2'])\n",
    "        single_file_name = file_name.split('/')[-1]\n",
    "        return_path = f\"{stream_s3_uri}/{single_file_name}\"\n",
    "        \n",
    "    return return_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f2cc57f-b61f-48ef-8d7b-580f47f66d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'M': 1, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"molecular-unfolding\"\n",
    "data_path = \"molecular-unfolding-data\"\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"M\": [1]},\n",
    "        {\"D\": [8]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2062d7b-b958-4c35-bf9f-202480d4d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-us-east-1-002224604296/molecular-unfolding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path)\n",
    "print(f\"upload data to s3 path: {s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320b1c6b-c575-4d41-a69a-cde747d903cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 002224604296 in region us-east-1: 002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-molecular-unfolding-jobs:latest\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "# # Uncomment the following code if you want to rebuild the container\n",
    "# !sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1d52f18-791a-4943-abaf-1a9911815709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to get null: list index out of range, use sv1 instead\n",
      "Creating molecular-unfolding with M 1 and D 8\n"
     ]
    }
   ],
   "source": [
    "# parse evaluation parameters and trigger hybrid jobs:\n",
    "jobs = []\n",
    "names = []\n",
    "\n",
    "job_name = f\"{experiment_name}-job\"\n",
    "\n",
    "# from braket.jobs.local import LocalQuantumJob\n",
    "\n",
    "for job_param in hybrid_job_params:\n",
    "    M = job_param['M']\n",
    "    D = job_param['D']\n",
    "    quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "    classical_device = job_param['device']['cc']\n",
    "    \n",
    "    print(f\"Creating {experiment_name} with M {M} and D {D}\")\n",
    "    name = f\"{experiment_name}-M-{M}-D-{D}-\" + str(int(time.time()))\n",
    "    \n",
    "    # print(f\"parameters for quantum job: \\n \\\n",
    "    # quantu_device {quantum_device} \\n \\\n",
    "    # experiment_name {experiment_name} \\n \\\n",
    "    # entry_point {experiment_name}.{job_name}:main \\n \\\n",
    "    # name {name} \\n \\\n",
    "    # job_param {job_param} \\n \\\n",
    "    # s3_path {s3_path} \\n \\\n",
    "    # classical_device {classical_device} \\n \\\n",
    "    # image_uri {image_uri} \")\n",
    "\n",
    "    tmp_job = AwsQuantumJob.create(\n",
    "        device=quantum_device,\n",
    "        source_module=f\"{experiment_name}\",\n",
    "        entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "        job_name=name,\n",
    "        hyperparameters=job_param,\n",
    "        input_data=s3_path,\n",
    "        instance_config=InstanceConfig(instanceType=classical_device),\n",
    "        image_uri=image_uri,\n",
    "        wait_until_complete=False,\n",
    "    )\n",
    "    \n",
    "    # tmp_job = LocalQuantumJob.create(\n",
    "    #     device=quantum_device,\n",
    "    #     source_module=f\"{experiment_name}\",\n",
    "    #     entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "    #     job_name=name,\n",
    "    #     hyperparameters=job_param,\n",
    "    #     input_data=s3_path,\n",
    "    #     image_uri=image_uri,\n",
    "    # )\n",
    "    jobs.append(tmp_job)\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2ad0db6-ad34-410f-ac39-092649a83ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_job_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cb22230-7feb-4ec0-a782-48b3eb2165af",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_arn = []\n",
    "\n",
    "for job in jobs:\n",
    "    jobs_arn.append(job.arn)\n",
    "\n",
    "jobs_states = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"hybrid-jobs-arn\": jobs_arn,\n",
    "    \"names\": names\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65daef94-d894-4ea9-bf5c-23a7cbe8ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hybrid job arn for further analysis\n",
    "json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a643773a-ecaa-4af5-a7eb-ed276f7930b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job molecular-unfolding-M-1-D-8-1672738111 is : COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# recover hybrid jobs and show result\n",
    "jobs_states_load = None\n",
    "with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "    jobs_states_load = json.load(outfile)\n",
    "\n",
    "for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "    current_job = AwsQuantumJob(job_arn)\n",
    "    print(f\"the state of job {job_name} is : {current_job.state()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f32e4-c3c8-475c-9d8c-1d122ce42baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
