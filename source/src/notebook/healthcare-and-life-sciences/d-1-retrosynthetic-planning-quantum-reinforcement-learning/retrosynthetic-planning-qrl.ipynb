{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa8a212",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2fe146",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utility.RetroRLAgent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# from utility.RetroParser import RetroData\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutility\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mRetroGateModel\u001b[39;00m \u001b[39mimport\u001b[39;00m RetroRLModel\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutility\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mRetroRLAgent\u001b[39;00m \u001b[39mimport\u001b[39;00m RetroRLAgent\n\u001b[1;32m      4\u001b[0m \u001b[39m# from utility.ResultProcess import ResultParser\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutility\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDataPrepare\u001b[39;00m \u001b[39mimport\u001b[39;00m Prepare\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utility.RetroRLAgent'"
     ]
    }
   ],
   "source": [
    "# from utility.RetroParser import RetroData\n",
    "from utility.RetroGateModel import RetroRLModel\n",
    "from utility.RetroRLAgent import RetroRLAgent\n",
    "# from utility.ResultProcess import ResultParser\n",
    "from utility.DataPrepare import Prepare\n",
    "from utility.BruteForceSearch import expansion, Product, Reaction\n",
    "import time\n",
    "import numpy as np\n",
    "# # Use Braket SDK Cost Tracking to estimate the cost to run this example\n",
    "# from braket.tracking import Tracker\n",
    "# t = Tracker().start()\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c6b938",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we load the retrosynthesis prediction data for experiment.\n",
    "The [USPTO-50K](https://tdcommons.ai/generation_tasks/retrosyn/#uspto-50k) was \n",
    "put in the repository. We assign the relative \n",
    "path to **raw_path**.\n",
    "The **s3_bucket** and **prefix** are used to store the \n",
    "results. We can use the one created with the \n",
    "cloudformation for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655b6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-04-26 14:09:50--  https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
      "Resolving d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)... 18.155.70.118, 18.155.70.191, 18.155.70.129, ...\n",
      "Connecting to d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)|18.155.70.118|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3841896 (3.7M) [application/zip]\n",
      "Saving to: 'retrosynthetic-plannin-dataset.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  630K 6s\n",
      "    50K .......... .......... .......... .......... ..........  2%  864K 5s\n",
      "   100K .......... .......... .......... .......... ..........  3% 2.58M 4s\n",
      "   150K .......... .......... .......... .......... ..........  5% 1.20M 3s\n",
      "   200K .......... .......... .......... .......... ..........  6% 2.05M 3s\n",
      "   250K .......... .......... .......... .......... ..........  7% 3.04M 3s\n",
      "   300K .......... .......... .......... .......... ..........  9% 1.09M 3s\n",
      "   350K .......... .......... .......... .......... .......... 10% 3.33M 2s\n",
      "   400K .......... .......... .......... .......... .......... 11% 3.58M 2s\n",
      "   450K .......... .......... .......... .......... .......... 13% 11.8M 2s\n",
      "   500K .......... .......... .......... .......... .......... 14% 7.62M 2s\n",
      "   550K .......... .......... .......... .......... .......... 15% 1.48M 2s\n",
      "   600K .......... .......... .......... .......... .......... 17% 11.6M 2s\n",
      "   650K .......... .......... .......... .......... .......... 18% 10.6M 2s\n",
      "   700K .......... .......... .......... .......... .......... 19% 9.01M 1s\n",
      "   750K .......... .......... .......... .......... .......... 21% 5.06M 1s\n",
      "   800K .......... .......... .......... .......... .......... 22% 14.3M 1s\n",
      "   850K .......... .......... .......... .......... .......... 23% 12.8M 1s\n",
      "   900K .......... .......... .......... .......... .......... 25% 7.94M 1s\n",
      "   950K .......... .......... .......... .......... .......... 26% 13.6M 1s\n",
      "  1000K .......... .......... .......... .......... .......... 27% 14.1M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 29% 8.32M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 30% 2.58M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 31% 13.7M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 33% 3.98M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 34%  269M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 35% 11.6M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 37% 86.0M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 38% 25.5M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 39% 2.57M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 41%  179M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 42% 8.65M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 43%  483M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 45% 14.8M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 46% 5.33M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 47% 6.86M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 49%  105M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 50%  169M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 51%  127M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 53% 6.86M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 54%  228M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 55% 15.5M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 57%  215M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 58% 4.54M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 59% 2.30M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 61%  127M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 62%  190M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 63%  298M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 65%  135M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 66% 87.2M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 67% 36.5M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 69% 6.51M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 70%  213M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 71%  274M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 73% 12.1M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 74% 5.59M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 75% 13.4M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 77%  226M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 78% 5.91M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 79%  127M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 81%  194M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 82% 8.73M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 83% 15.2M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 85% 10.9M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 86%  251M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 87% 15.0M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 89% 7.15M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 90%  201M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 91% 6.66M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 93% 13.0M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 94%  144M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 95%  253M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 97% 4.39M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 98% 17.7M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 99%  156M 0s\n",
      "  3750K .                                                     100% 35.3G=0.6s\n",
      "\n",
      "2023-04-26 14:09:51 (5.91 MB/s) - 'retrosynthetic-plannin-dataset.zip' saved [3841896/3841896]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  retrosynthetic-plannin-dataset.zip\n",
      "   creating: retrosynthetic-planning-dataset/\n",
      "  inflating: retrosynthetic-planning-dataset/buyable.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/target_product.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/reactions_dictionary.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_map.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/ground_truth.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/Deadend.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/uspto50k.xlsx  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_dictionary.npy  \n",
      "retrosynthetic-planning-dataset\\buyable.npy\n",
      "retrosynthetic-planning-dataset\\Deadend.npy\n",
      "retrosynthetic-planning-dataset\\ground_truth.npy\n",
      "retrosynthetic-planning-dataset\\reactions_dictionary.npy\n",
      "retrosynthetic-planning-dataset\\smiles_dictionary.npy\n",
      "retrosynthetic-planning-dataset\\smiles_map.npy\n",
      "retrosynthetic-planning-dataset\\target_product.npy\n",
      "retrosynthetic-planning-dataset\\uspto50k.xlsx\n",
      "已复制         8 个文件。\n",
      "已复制         1 个文件。\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# download dateset\n",
    "!mkdir $data_path\n",
    "!mkdir $data_path\\smiles\n",
    "!wget https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
    "!unzip retrosynthetic-plannin-dataset.zip\n",
    "# windows\n",
    "!copy retrosynthetic-planning-dataset $data_path\n",
    "!copy data\\smiles_map.npy  data\\smiles\\smiles_map.npy\n",
    "\n",
    "# linux\n",
    "# !cp retrosynthetic-planning-dataset $data_path\n",
    "# !cp data/smiles_map.npy  data/smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24175d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Files are present.\n",
      "INFO:root:All files are generated!\n",
      "INFO:root:File is present.\n"
     ]
    }
   ],
   "source": [
    "# input: predata_uspto-50k.xlsx\n",
    "# output: file1.npy,file2.npy\n",
    "raw_path = 'data/uspto50k.xlsx'\n",
    "prepare = Prepare(raw_path)\n",
    "prepare.generate_files()  # \n",
    "prepare.generate_ground_truth()\n",
    "ground_truth = np.load(prepare.path+'ground_truth.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8431116a",
   "metadata": {},
   "source": [
    "#### Step 2: Build Model\n",
    "\n",
    "In this part, we build the circuit model for retrosynthetic planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89c4c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n"
     ]
    }
   ],
   "source": [
    "# initial the RetroRLModel object\n",
    "init_param = {}\n",
    "method = ['retro-rl', 'retro-qrl']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'retro-rl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['inputsize', 'middlesize', 'outputsize']\n",
    "    elif mt == 'retro-qrl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['n_qubits', 'device', 'framework', 'shots', 'layers']\n",
    "    \n",
    "retro_rl_model = RetroRLModel(data=None, method=method, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4ea6e07-8dc2-4a44-bb18-285f6b576fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for inputsize:256,middlesize:256,outputsize:1 0.0 min\n",
      "INFO:root:Construct model for inputsize:256,middlesize:512,outputsize:1 1.665353775024414e-05 min\n",
      "INFO:root:Construct model for inputsize:256,middlesize:1024,outputsize:1 1.6490618387858074e-05 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-rl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['inputsize'] = [256]\n",
    "model_param[method]['middlesize'] = [256,512,1024]\n",
    "model_param[method]['outputsize'] = [1]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aa1f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 1.6649564107259113e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:2 1.6673405965169272e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:3 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:2 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:3 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:1 1.6756852467854817e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:2 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:3 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:1 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:2 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:3 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:1 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:2 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:3 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:1 1.6792615254720053e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:2 0.0 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:3 0.0 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-qrl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['n_qubits'] = [8]\n",
    "model_param[method]['device'] = ['local', 'sv1', 'aspen-m2']\n",
    "model_param[method]['framework'] = ['pennylane']\n",
    "model_param[method]['shots'] = [100,1000]\n",
    "model_param[method]['layers'] = [1,2,3]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9624b3f",
   "metadata": {},
   "source": [
    "We can use the following method to check the properties of \n",
    "model. This way, we can build many models conveniently. \n",
    "After that, we save the model and update the value of \n",
    "**model_path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "431a9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {256, 512, 1024}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'sv1', 'aspen-m2', 'local'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {1000, 100}\n",
      "INFO:root:param: layers, value {1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# describe the model parameters\n",
    "model_info = retro_rl_model.describe_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cfdc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save retrorl_model_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the nn model for RL and saved it as .\\retrorl_model_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = retro_rl_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the nn model for RL and saved it as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b54a25-9ef1-4e2c-a591-def2a1322db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已复制         1 个文件。\n"
     ]
    }
   ],
   "source": [
    "# !cp $model_path $data_path\n",
    "\n",
    "# windows\n",
    "!copy $model_path $data_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb42eb0f",
   "metadata": {},
   "source": [
    "#### Step 3: Learn Retrosynthetic Planning\n",
    "\n",
    "In this part, we use cpu to run classical model for retrosynthetic planning \n",
    "and simulators/NISQ devices to run quantum model for retrosysnthetic planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edad7abf-cdd6-4629-8bc7-8e3b4054b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'sv1'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baba9dfc-ca51-43a1-b7bf-9459f3459402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8537e938-942f-4357-92d8-95af3735de99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run sv1 mode\n",
      "create job with arn arn:aws:braket:us-west-1:493904798517:job/retrorl-job-sv1-torch-1682489607\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085067ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CANCELLING'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f803eb8-3a13-4e6b-87f7-2882d8c3ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run local mode\n",
      "create job with arn arn:aws:braket:us-west-1:493904798517:job/retrorl-job-local-torch-1682400869\n"
     ]
    }
   ],
   "source": [
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e06d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CANCELLING'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b5708-61f0-4427-863f-a3769faa984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'\n",
    "\n",
    "n_qubits = 8\n",
    "device = 'aspen-m2'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80958946-4527-41f3-9b21-e13c77179a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "inputsize = 256\n",
    "middlesize = 512\n",
    "outputsize = 1\n",
    "\n",
    "model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "method = \"retro-rl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab975431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_rl_model = RetroRLModel.load(model_path)\n",
    "model_info = retro_rl_model.describe_model()\n",
    "retro_model = retro_rl_model.get_model(method, model_name)\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game()\n",
    "retro_rl_agent.save(\"latest\", path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_path = retro_rl_agent.save(\"latest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddcba0ff",
   "metadata": {},
   "source": [
    "#### Step 4: PostProcess Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3587c890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {512}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'sv1', 'aspen-m2', 'local'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {100}\n",
      "INFO:root:param: layers, value {1, 2, 3}\n",
      "INFO:root:load data...\n",
      "INFO:root:model is {'model_name': '8_local_pennylane_100_2', 'version': '1682575107', 'nn_model': CirModel()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('episode', 1)\n",
      "('episode', 2)\n",
      "('episode', 3)\n",
      "('episode', 4)\n",
      "('episode', 5)\n",
      "('episode', 6)\n",
      "('episode', 7)\n",
      "('episode', 8)\n",
      "('episode', 9)\n",
      "('episode', 10)\n",
      "('episode', 11)\n",
      "('episode', 12)\n",
      "('episode', 13)\n",
      "('episode', 14)\n",
      "('episode', 15)\n",
      "('episode', 16)\n",
      "('episode', 17)\n",
      "('episode', 18)\n",
      "('episode', 19)\n",
      "('episode', 20)\n",
      "epsiode 20 training...\n",
      "Parameter containing:\n",
      "tensor([[5.6262, 0.4769, 4.2342, 4.5672, 1.8381, 3.4660, 4.2988, 2.5562],\n",
      "        [4.5192, 0.0290, 2.0298, 2.7523, 2.2296, 6.2124, 0.8331, 4.7189]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_83516\\97261432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mretro_rl_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRetroRLAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretro_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0magent_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mretro_rl_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\new\\quantum-computing-exploration-for-drug-discovery-on-aws\\source\\src\\notebook\\healthcare-and-life-sciences\\retrosynthetic-planning-reinforcement-learning\\utility\\RetroRLAgent.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mRetroRLAgent.RetroRLAgent.game_job\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\new\\quantum-computing-exploration-for-drug-discovery-on-aws\\source\\src\\notebook\\healthcare-and-life-sciences\\retrosynthetic-planning-reinforcement-learning\\utility\\RetroRLAgent.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mRetroRLAgent.RetroRLAgent.game\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\new\\quantum-computing-exploration-for-drug-discovery-on-aws\\source\\src\\notebook\\healthcare-and-life-sciences\\retrosynthetic-planning-reinforcement-learning\\utility\\RetroRLAgent.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mRetroRLAgent.RetroRLAgent.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    251\u001b[0m                                \"of them.\")\n\u001b[0;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\interfaces\\torch.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(ctx, *dy)\u001b[0m\n\u001b[0;32m    173\u001b[0m                         )\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                         \u001b[0mvjps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessing_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp_tapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\interfaces\\execution.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;31m# execute all unique tapes that do not exist in the cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_tapes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mfinal_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\interfaces\\execution.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=function-redefined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mtapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\interfaces\\execution.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=function-redefined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mtapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\interfaces\\execution.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(tape)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexpand_fn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"device\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mexpand_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_expansion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_expansion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgradient_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\_device.py\u001b[0m in \u001b[0;36mexpand_fn\u001b[1;34m(self, circuit, max_expansion)\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_expand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_expansion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_expansion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_expand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_expansion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_expansion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\_device.py\u001b[0m in \u001b[0;36mdefault_expand_fn\u001b[1;34m(self, circuit, max_expansion)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mops_not_supported\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobs_on_same_wire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m             \u001b[0mcircuit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_expansion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_at\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopping_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexpand\u001b[1;34m(self, depth, stop_at, expand_measurements)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m    612\u001b[0m         new_tape = expand_tape(\n\u001b[1;32m--> 613\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_at\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_measurements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand_measurements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[0mnew_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexpand_tape\u001b[1;34m(tape, depth, stop_at, expand_measurements)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;31m# recursively expand out the newly created tape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mexpanded_tape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_tape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_at\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mnew_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mexpanded_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexpand_tape\u001b[1;34m(tape, depth, stop_at, expand_measurements)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;31m# recursively expand out the newly created tape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mexpanded_tape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_tape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_at\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mnew_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mexpanded_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexpand_tape\u001b[1;34m(tape, depth, stop_at, expand_measurements)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;31m# Object is an operation; query it for its expansion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mDecompositionUndefinedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                     \u001b[1;31m# Object does not define an expansion; treat this as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\operation.py\u001b[0m in \u001b[0;36mexpand\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\operation.py\u001b[0m in \u001b[0;36mdecomposition\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \"\"\"\n\u001b[0;32m   1037\u001b[0m         return self.compute_decomposition(\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m         )\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\templates\\state_preparations\\mottonen.py\u001b[0m in \u001b[0;36mcompute_decomposition\u001b[1;34m(state_vector, wires)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwires_reverse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwires_reverse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mop_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_apply_uniform_rotation_dagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_y_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;31m# If necessary, apply inverse z rotation cascade to prepare correct phases of amplitudes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\templates\\state_preparations\\mottonen.py\u001b[0m in \u001b[0;36m_apply_uniform_rotation_dagger\u001b[1;34m(gate, alpha, control_wires, target_wire)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m    120\u001b[0m     \u001b[0mop_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mgray_code_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_wires\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\templates\\state_preparations\\mottonen.py\u001b[0m in \u001b[0;36mcompute_theta\u001b[1;34m(alpha)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_trans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mM_trans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_matrix_M_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\py379\\lib\\site-packages\\pennylane\\templates\\state_preparations\\mottonen.py\u001b[0m in \u001b[0;36m_matrix_M_entry\u001b[1;34m(row, col)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mb_and_g\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mb_and_g\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0b1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0msum_of_ones\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mb_and_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_and_g\u001b[0m \u001b[1;33m>>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "layers = 2\n",
    "\n",
    "model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"local-instance\"\n",
    "\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "419f2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {512}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'aspen-m2', 'local', 'sv1'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {100}\n",
      "INFO:root:param: layers, value {1, 2, 3}\n",
      "INFO:root:load data...\n",
      "INFO:root:model is {'model_name': '256_512_1', 'version': '1682491773', 'nn_model': Model(\n",
      "  (relu): ReLU()\n",
      "  (value_fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (value_fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('episode', 1)\n",
      "('episode', 2)\n",
      "('episode', 3)\n",
      "('episode', 4)\n",
      "('episode', 5)\n",
      "('episode', 6)\n",
      "('episode', 7)\n",
      "('episode', 8)\n",
      "('episode', 9)\n",
      "('episode', 10)\n",
      "('episode', 11)\n",
      "('episode', 12)\n",
      "('episode', 13)\n",
      "('episode', 14)\n",
      "('episode', 15)\n",
      "('episode', 16)\n",
      "('episode', 17)\n",
      "('episode', 18)\n",
      "('episode', 19)\n",
      "('episode', 20)\n",
      "epsiode 20 training...\n",
      "finish epoch 0 for 4.9996376037597654e-05 minutes\n",
      "finish epoch 1 for 3.337860107421875e-05 minutes\n",
      "finish epoch 2 for 1.665353775024414e-05 minutes\n",
      "finish epoch 3 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 4 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 5 for 1.668532689412435e-05 minutes\n",
      "finish epoch 6 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 7 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 8 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 9 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 10 for 1.666545867919922e-05 minutes\n",
      "finish epoch 11 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 12 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 13 for 1.6689300537109375e-05 minutes\n",
      "finish epoch 14 for 3.350178400675456e-05 minutes\n",
      "finish epoch 15 for 1.6486644744873048e-05 minutes\n",
      "finish epoch 16 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 17 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 18 for 1.6629695892333984e-05 minutes\n",
      "finish epoch 19 for 3.3346811930338543e-05 minutes\n",
      "('episode', 21)\n",
      "('episode', 22)\n",
      "('episode', 23)\n",
      "('episode', 24)\n",
      "('episode', 25)\n",
      "('episode', 26)\n",
      "('episode', 27)\n",
      "('episode', 28)\n",
      "('episode', 29)\n",
      "('episode', 30)\n",
      "('episode', 31)\n",
      "('episode', 32)\n",
      "('episode', 33)\n",
      "('episode', 34)\n",
      "('episode', 35)\n",
      "('episode', 36)\n",
      "('episode', 37)\n",
      "('episode', 38)\n",
      "('episode', 39)\n",
      "('episode', 40)\n",
      "epsiode 40 training...\n",
      "finish epoch 0 for 1.6156832377115885e-05 minutes\n",
      "finish epoch 1 for 1.6645590464274088e-05 minutes\n",
      "finish epoch 2 for 1.666545867919922e-05 minutes\n",
      "finish epoch 3 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 4 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 5 for 1.666545867919922e-05 minutes\n",
      "finish epoch 6 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 7 for 1.666545867919922e-05 minutes\n",
      "finish epoch 8 for 1.666545867919922e-05 minutes\n",
      "finish epoch 9 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 10 for 1.666545867919922e-05 minutes\n",
      "finish epoch 11 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 12 for 1.666545867919922e-05 minutes\n",
      "finish epoch 13 for 1.666545867919922e-05 minutes\n",
      "finish epoch 14 for 1.666545867919922e-05 minutes\n",
      "finish epoch 15 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 16 for 1.6637643178304036e-05 minutes\n",
      "finish epoch 17 for 1.666545867919922e-05 minutes\n",
      "finish epoch 18 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 19 for 1.6669432322184246e-05 minutes\n",
      "('episode', 41)\n",
      "('episode', 42)\n",
      "('episode', 43)\n",
      "('episode', 44)\n",
      "('episode', 45)\n",
      "('episode', 46)\n",
      "('episode', 47)\n",
      "('episode', 48)\n",
      "('episode', 49)\n",
      "('episode', 50)\n",
      "('episode', 51)\n",
      "('episode', 52)\n",
      "('episode', 53)\n",
      "('episode', 54)\n",
      "('episode', 55)\n",
      "('episode', 56)\n",
      "('episode', 57)\n",
      "('episode', 58)\n",
      "('episode', 59)\n",
      "('episode', 60)\n",
      "epsiode 60 training...\n",
      "finish epoch 0 for 3.281831741333008e-05 minutes\n",
      "finish epoch 1 for 1.6597906748453774e-05 minutes\n",
      "finish epoch 2 for 1.666545867919922e-05 minutes\n",
      "finish epoch 3 for 1.666545867919922e-05 minutes\n",
      "finish epoch 4 for 1.666545867919922e-05 minutes\n",
      "finish epoch 5 for 1.666545867919922e-05 minutes\n",
      "finish epoch 6 for 1.666545867919922e-05 minutes\n",
      "finish epoch 7 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 8 for 1.666545867919922e-05 minutes\n",
      "finish epoch 9 for 1.666545867919922e-05 minutes\n",
      "finish epoch 10 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 11 for 1.666545867919922e-05 minutes\n",
      "finish epoch 12 for 1.666545867919922e-05 minutes\n",
      "finish epoch 13 for 1.666545867919922e-05 minutes\n",
      "finish epoch 14 for 1.666545867919922e-05 minutes\n",
      "finish epoch 15 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 16 for 1.666545867919922e-05 minutes\n",
      "finish epoch 17 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 18 for 3.333489100138346e-05 minutes\n",
      "finish epoch 19 for 1.666545867919922e-05 minutes\n",
      "('episode', 61)\n",
      "('episode', 62)\n",
      "('episode', 63)\n",
      "('episode', 64)\n",
      "('episode', 65)\n",
      "('episode', 66)\n",
      "('episode', 67)\n",
      "('episode', 68)\n",
      "('episode', 69)\n",
      "('episode', 70)\n",
      "('episode', 71)\n",
      "('episode', 72)\n",
      "('episode', 73)\n",
      "('episode', 74)\n",
      "('episode', 75)\n",
      "('episode', 76)\n",
      "('episode', 77)\n",
      "('episode', 78)\n",
      "('episode', 79)\n",
      "('episode', 80)\n",
      "epsiode 80 training...\n",
      "finish epoch 0 for 3.277063369750976e-05 minutes\n",
      "finish epoch 1 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 2 for 1.6717116038004556e-05 minutes\n",
      "finish epoch 3 for 1.6617774963378907e-05 minutes\n",
      "finish epoch 4 for 1.666545867919922e-05 minutes\n",
      "finish epoch 5 for 1.666545867919922e-05 minutes\n",
      "finish epoch 6 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 7 for 1.666545867919922e-05 minutes\n",
      "finish epoch 8 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 9 for 1.666545867919922e-05 minutes\n",
      "finish epoch 10 for 1.666545867919922e-05 minutes\n",
      "finish epoch 11 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 12 for 1.666545867919922e-05 minutes\n",
      "finish epoch 13 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 14 for 1.666545867919922e-05 minutes\n",
      "finish epoch 15 for 1.666545867919922e-05 minutes\n",
      "finish epoch 16 for 1.666545867919922e-05 minutes\n",
      "finish epoch 17 for 1.666545867919922e-05 minutes\n",
      "finish epoch 18 for 1.666545867919922e-05 minutes\n",
      "finish epoch 19 for 1.6661485036214194e-05 minutes\n",
      "('episode', 81)\n",
      "('episode', 82)\n",
      "('episode', 83)\n",
      "('episode', 84)\n",
      "('episode', 85)\n",
      "('episode', 86)\n",
      "('episode', 87)\n",
      "('episode', 88)\n",
      "('episode', 89)\n",
      "('episode', 90)\n",
      "('episode', 91)\n",
      "('episode', 92)\n",
      "('episode', 93)\n",
      "('episode', 94)\n",
      "('episode', 95)\n",
      "('episode', 96)\n",
      "('episode', 97)\n",
      "('episode', 98)\n",
      "('episode', 99)\n",
      "('episode', 100)\n",
      "epsiode 100 training...\n",
      "finish epoch 0 for 3.2691160837809247e-05 minutes\n",
      "finish epoch 1 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 2 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 3 for 1.666545867919922e-05 minutes\n",
      "finish epoch 4 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 5 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 6 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 7 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 8 for 1.666545867919922e-05 minutes\n",
      "finish epoch 9 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 10 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 11 for 1.666545867919922e-05 minutes\n",
      "finish epoch 12 for 1.666545867919922e-05 minutes\n",
      "finish epoch 13 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 14 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 15 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 16 for 1.666545867919922e-05 minutes\n",
      "finish epoch 17 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 18 for 1.666545867919922e-05 minutes\n",
      "finish epoch 19 for 1.6661485036214194e-05 minutes\n"
     ]
    }
   ],
   "source": [
    "# get the model you want to optimize\n",
    "inputsize = 256\n",
    "middlesize = 512\n",
    "outputsize = 1\n",
    "\n",
    "model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "method = \"retro-rl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"local-instance\"\n",
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_rl_model = RetroRLModel.load(model_path)\n",
    "model_info = retro_rl_model.describe_model()\n",
    "retro_model = retro_rl_model.get_model(method, model_name)\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd3c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'Cc1ccc(S(=O)(=O)O)cc1', 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'O=C(O)[C@@H]1CCCN1', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'Cc1ccc(S(=O)(=O)O)cc1', 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'O=C(O)[C@@H]1CCCN1', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  102.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f58dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  3.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'O=C(NCc1ccc(CO)cc1)c1ccccn1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634c442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(c1ccccc1)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(c1ccccc1)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_cost of Brute force: \n",
      "  2.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "902bfb14",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsQuantumJob\n",
    "from braket.jobs.config import InstanceConfig\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utility.HybridJobHelpers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66eb11a1",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare parameters for batch evaluation\n",
    "\n",
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100]},\n",
    "        {\"device\": ['local']}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_param={}\n",
    "# method = 'retro-qrl'\n",
    "# model_param[method] = {}\n",
    "# model_param[method]['n_qubits'] = [8]\n",
    "# model_param[method]['device'] = ['local', 'sv1', 'aspen-m2']\n",
    "# model_param[method]['framework'] = ['pennylane']\n",
    "# model_param[method]['shots'] = [100]\n",
    "# model_param[method]['layers'] = [1,2,3]\n",
    "\n",
    "\n",
    "# # get the model you want to optimize\n",
    "# n_qubits = 8\n",
    "# device = 'local'\n",
    "# framework = 'pennylane'\n",
    "# shots = 100\n",
    "# layers = 2\n",
    "\n",
    "# model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "# method = \"retro-qrl\"\n",
    "\n",
    "# # train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "# train_mode = \"local-instance\"\n",
    "\n",
    "# data_path = 'data'\n",
    "# agent_param = {}\n",
    "# agent_param[\"data_path\"] = data_path\n",
    "# agent_param[\"train_mode\"] = train_mode\n",
    "# agent_param[\"model_name\"] = model_name\n",
    "# agent_param[\"model_path\"] = model_path\n",
    "\n",
    "# retro_model = None\n",
    "# if train_mode == \"local-instance\":\n",
    "#     # get model\n",
    "#     retro_rl_model = RetroRLModel.load(model_path)\n",
    "#     model_info = retro_rl_model.describe_model()\n",
    "#     retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "# retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "# retro_rl_agent.game_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_param={}\n",
    "# method = 'retro-rl'\n",
    "# model_param[method] = {}\n",
    "# model_param[method]['inputsize'] = [256]\n",
    "# model_param[method]['middlesize'] = [512]\n",
    "# model_param[method]['outputsize'] = [1]\n",
    "\n",
    "\n",
    "# # get the model you want to optimize\n",
    "# inputsize = 256\n",
    "# middlesize = 512\n",
    "# outputsize = 1\n",
    "\n",
    "# model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "# method = \"retro-rl\"\n",
    "\n",
    "# # train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "# train_mode = \"local-instance\"\n",
    "# data_path = 'data'\n",
    "# agent_param = {}\n",
    "# agent_param[\"data_path\"] = data_path\n",
    "# agent_param[\"train_mode\"] = train_mode\n",
    "# agent_param[\"model_name\"] = model_name\n",
    "# agent_param[\"model_path\"] = model_path\n",
    "\n",
    "# retro_rl_model = RetroRLModel.load(model_path)\n",
    "# model_info = retro_rl_model.describe_model()\n",
    "# retro_model = retro_rl_model.get_model(method, model_name)\n",
    "# retro_rl_agent1 = RetroRLAgent(retro_model, method, **agent_param)\n",
    "# retro_rl_agent1.game_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b67a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params1\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100,1000]},\n",
    "        {\"device\": ['local']}\n",
    "    ],\n",
    "    \"params2\": [\n",
    "        {\"inputsize\": [256]},\n",
    "        {\"middlesize\": [256,512,1024]},\n",
    "        {\"outputsize\": [1]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# hp = {}\n",
    "# hybrid_job_params = []\n",
    "# parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "# print(f\"parameters for experiments: \\n {hybrid_job_params}\")\n",
    "\n",
    "hybrid_job_params = []\n",
    "for n_qubits in experiments_params['params1'][0][\"n_qubits\"]:\n",
    "    for framework in experiments_params['params1'][1][\"framework\"]:\n",
    "            for layers in experiments_params['params1'][2][\"layers\"]:\n",
    "                for shots in experiments_params['params1'][3][\"shots\"]:\n",
    "                    for device in experiments_params['params1'][4][\"device\"]:\n",
    "                        model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "                        hybrid_job_params.append(model_name)\n",
    "for inputsize in experiments_params['params2'][0][\"inputsize\"]:\n",
    "    for middlesize in experiments_params['params2'][1][\"middlesize\"]:\n",
    "            for outputsize in experiments_params['params2'][2][\"outputsize\"]:                \n",
    "                model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "                hybrid_job_params.append(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8593ee25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8_local_pennylane_100_1',\n",
       " '8_local_pennylane_1000_1',\n",
       " '8_local_pennylane_100_2',\n",
       " '8_local_pennylane_1000_2',\n",
       " '8_local_pennylane_100_3',\n",
       " '8_local_pennylane_1000_3',\n",
       " '256_256_1',\n",
       " '256_512_1',\n",
       " '256_1024_1']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avtocost = []\n",
    "for i in hybrid_job_params:\n",
    "    model_name = hybrid_job_params[i]\n",
    "    if model_name[0] == \"8\":\n",
    "        method = \"retro-qrl\"\n",
    "    else:\n",
    "        method = \"retro-rl\"\n",
    "    \n",
    "\n",
    "    # train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "    train_mode = \"local-instance\"\n",
    "\n",
    "    data_path = 'data'\n",
    "    agent_param = {}\n",
    "    agent_param[\"data_path\"] = data_path\n",
    "    agent_param[\"train_mode\"] = train_mode\n",
    "    agent_param[\"model_name\"] = model_name\n",
    "    agent_param[\"model_path\"] = model_path\n",
    "\n",
    "    retro_model = None\n",
    "    if train_mode == \"local-instance\":\n",
    "        # get model\n",
    "        retro_rl_model = RetroRLModel.load(model_path)\n",
    "        model_info = retro_rl_model.describe_model()\n",
    "        retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "    retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "    retro_rl_agent.game_job()\n",
    "    avtocost.append(retro_rl_agent.avtocost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the training curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.title('Training curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average cost')\n",
    "for i in range(len(hybrid_job_params)):\n",
    "    plt.plot(range(0,len(avtocost[0])),avtocost[i],label=hybrid_job_params[i])\n",
    "plt.legend(loc = 'upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc_hcls_retrosynthetic_planning_qrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
