{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199a63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa8a212",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2fe146",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from hybridjobs.utility.RetroGateModel import RetroRLModel\n",
    "from hybridjobs.utility.RetroRLAgent import RetroRLAgent\n",
    "from hybridjobs.utility.DataPrepare import Prepare\n",
    "from hybridjobs.utility.BruteForceSearch import expansion, Product, Reaction\n",
    "import time\n",
    "import numpy as np\n",
    "# # Use Braket SDK Cost Tracking to estimate the cost to run this example\n",
    "# from braket.tracking import Tracker\n",
    "# t = Tracker().start()\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e057ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c6b938",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we load the retrosynthesis prediction data for experiment.\n",
    "The [USPTO-50K](https://tdcommons.ai/generation_tasks/retrosyn/#uspto-50k) was \n",
    "put in the repository. We assign the relative \n",
    "path to **raw_path**.\n",
    "The **s3_bucket** and **prefix** are used to store the \n",
    "results. We can use the one created with the \n",
    "cloudformation for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655b6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘datasmiles’: File exists\n",
      "--2023-11-20 00:58:03--  https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
      "Resolving d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)... 108.156.178.143, 108.156.178.195, 108.156.178.18, ...\n",
      "Connecting to d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)|108.156.178.143|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3841896 (3.7M) [application/zip]\n",
      "Saving to: ‘retrosynthetic-plannin-dataset.zip’\n",
      "\n",
      "retrosynthetic-plan 100%[===================>]   3.66M  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-11-20 00:58:03 (230 MB/s) - ‘retrosynthetic-plannin-dataset.zip’ saved [3841896/3841896]\n",
      "\n",
      "Archive:  retrosynthetic-plannin-dataset.zip\n",
      "  inflating: retrosynthetic-planning-dataset/buyable.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/target_product.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/reactions_dictionary.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_map.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/ground_truth.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/Deadend.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/uspto50k.xlsx  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_dictionary.npy  \n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# download dateset\n",
    "!mkdir $data_path\n",
    "!mkdir $data_path\\smiles\n",
    "!wget https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
    "!unzip -o retrosynthetic-plannin-dataset.zip\n",
    "# # windows\n",
    "# !copy retrosynthetic-planning-dataset $data_path\n",
    "# !copy data\\smiles_map.npy  data\\smiles\\smiles_map.npy\n",
    "\n",
    "# linux\n",
    "!cp -r retrosynthetic-planning-dataset/* $data_path\n",
    "!cp data/smiles_map.npy  data/smiles\n",
    "!rm retrosynthetic-plannin-dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24175d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Files are present.\n",
      "INFO:root:All files are generated!\n",
      "INFO:root:File is present.\n"
     ]
    }
   ],
   "source": [
    "# input: predata_uspto-50k.xlsx\n",
    "# output: file1.npy,file2.npy\n",
    "raw_path = 'data/uspto50k.xlsx'\n",
    "prepare = Prepare(raw_path)\n",
    "prepare.generate_files()  # \n",
    "prepare.generate_ground_truth()\n",
    "ground_truth = np.load(prepare.path+'ground_truth.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8431116a",
   "metadata": {},
   "source": [
    "#### Step 2: Prepare parameters for agents\n",
    "\n",
    "In this part, we prepare agent parameters wihch iniclude initial parameters, model parameters and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29c1a12-7350-4b30-8da9-81964d343f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_param = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c4c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial the RetroRLModel object\n",
    "init_param = {}\n",
    "method = ['retro-rl', 'retro-qrl']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'retro-rl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['inputsize', 'middlesize', 'outputsize']\n",
    "    elif mt == 'retro-qrl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['n_qubits', 'device', 'framework', 'shots', 'layers']\n",
    "    \n",
    "# retro_rl_model = RetroRLModel(data=None, method=method, **init_param)\n",
    "agent_param['init_param'] = init_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7c64849-e0e4-4a46-8ff8-8fbcdf14fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param={}\n",
    "method = 'retro-qrl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['n_qubits'] = [8]\n",
    "# model_param[method]['device'] = ['local', 'sv1', 'aspen-m-3', 'aria-2']\n",
    "model_param[method]['device'] = ['local']\n",
    "model_param[method]['framework'] = ['pennylane']\n",
    "# model_param[method]['shots'] = [100,1000]\n",
    "model_param[method]['shots'] = [100]\n",
    "# model_param[method]['layers'] = [1,2,3]\n",
    "model_param[method]['layers'] = [1]\n",
    "\n",
    "\n",
    "agent_param['model_param'] = model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ea6e07-8dc2-4a44-bb18-285f6b576fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment the following parameters if you want to use classical methods\n",
    "# model_param={}\n",
    "# method = 'retro-rl'\n",
    "# model_param[method] = {}\n",
    "# model_param[method]['inputsize'] = [256]\n",
    "# # model_param[method]['middlesize'] = [256,512,1024]\n",
    "# model_param[method]['middlesize'] = [256]\n",
    "# model_param[method]['outputsize'] = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9a05d8-dfd7-4fc3-92cb-238847c7c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/Deadend.npy to s3://amazon-braket-us-west-1-002224604296/data/Deadend.npy\n",
      "upload: data/smiles_map.npy to s3://amazon-braket-us-west-1-002224604296/data/smiles_map.npy\n",
      "upload: data/smiles to s3://amazon-braket-us-west-1-002224604296/data/smiles\n",
      "upload: data/ground_truth.npy to s3://amazon-braket-us-west-1-002224604296/data/ground_truth.npy\n",
      "upload: data/reactions_dictionary.npy to s3://amazon-braket-us-west-1-002224604296/data/reactions_dictionary.npy\n",
      "upload: data/buyable.npy to s3://amazon-braket-us-west-1-002224604296/data/buyable.npy\n",
      "upload: data/target_product.npy to s3://amazon-braket-us-west-1-002224604296/data/target_product.npy\n",
      "upload: data/uspto50k.xlsx to s3://amazon-braket-us-west-1-002224604296/data/uspto50k.xlsx\n",
      "upload: data/smiles_dictionary.npy to s3://amazon-braket-us-west-1-002224604296/data/smiles_dictionary.npy\n"
     ]
    }
   ],
   "source": [
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"local-job\"\n",
    "\n",
    "n_qubits = model_param[method]['n_qubits'][0]\n",
    "device = model_param[method]['device'][0]\n",
    "framework = model_param[method]['framework'][0]\n",
    "shots = model_param[method]['shots'][0]\n",
    "layers = model_param[method]['layers'][0]\n",
    "\n",
    "model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "\n",
    "data_path = 'data'\n",
    "# please change the following s3 bucket to the one you can upload and download data\n",
    "s3_data_path = None\n",
    "if train_mode == \"local-job\" or train_mode == \"hybrid-job\":\n",
    "    s3_bucket_name = \"s3://xxxxxx\"\n",
    "    s3_data_path = f\"{s3_bucket_name}/data\"\n",
    "    import os\n",
    "    os.system(f\"aws s3 sync {data_path} {s3_data_path}\")\n",
    "\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"s3_data_path\"]=s3_data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "# agent_param[\"model_path\"] = model_path\n",
    "agent_param[\"episodes\"] = 2\n",
    "\n",
    "retro_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b084b0b6-b294-486f-9f3f-97b2f84ee88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_param': {'retro-rl': {'param': ['inputsize', 'middlesize', 'outputsize']}, 'retro-qrl': {'param': ['n_qubits', 'device', 'framework', 'shots', 'layers']}}, 'model_param': {'retro-qrl': {'n_qubits': [8], 'device': ['local'], 'framework': ['pennylane'], 'shots': [100], 'layers': [1]}}, 'data_path': 'data', 's3_data_path': 's3://amazon-braket-us-west-1-002224604296/data', 'train_mode': 'local-job', 'model_name': '8_local_pennylane_100_1', 'episodes': 2}\n"
     ]
    }
   ],
   "source": [
    "# show agent_param\n",
    "print(agent_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d03bd5-2593-4450-b9fa-91660799efa3",
   "metadata": {},
   "source": [
    "#### Step 3: Learn Retrosynthetic Planning\n",
    "\n",
    "In this part, we use cpu to run classical model for retrosynthetic planning \n",
    "and simulators/NISQ devices to run quantum model for retrosysnthetic planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbaed183-3e66-4b64-adcf-06611d0dc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:load data...\n",
      "INFO:root:build_model is False\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iinitial a new agent...\n",
      "Going to run local mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING:braket.jobs.local.local_job_container:Pulling docker container image. This may take a while.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "latest: Pulling from amazon-braket-pytorch-jobs\n",
      "Digest: sha256:0fb89a8a8455e0483c0b8cebd26e946d9e15cf3bc659d2b438a65209181bb08e\n",
      "Status: Image is up to date for 292282985366.dkr.ecr.us-west-1.amazonaws.com/amazon-braket-pytorch-jobs:latest\n",
      "292282985366.dkr.ecr.us-west-1.amazonaws.com/amazon-braket-pytorch-jobs:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:braket.jobs.local.local_job_container_setup:Using the long-lived AWS credentials found in session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boto3 Version:  1.28.53\n",
      "Beginning Setup\n",
      "Checking for Additional Requirements\n",
      "Additional Requirements Check Finished\n",
      "Running Code As Process\n",
      "Current Python Version- 3.10.8\n",
      "{'method': 'retro-qrl', 'model_name': '8_local_pennylane_100_1', 'p': '2', 'max_parallel': '10', 'num_iterations': '5', 'stepsize': '0.1', 'shots': '1000', 'interface': 'torch', 'train_mode': 'local-job', 'episodes': '2'}\n",
      "Can't find data in /opt/braket/input/data/input or /opt/braket/input/data/data!!!\n",
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:load data...\n",
      "iinitial a new agent...\n",
      "INFO:root:build_model is True\n",
      "model_param is {'retro-qrl': {'n_qubits': [8], 'device': ['local'], 'framework': ['pennylane'], 'shots': [100], 'layers': [1]}}\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 0.0008367816607157389 min\n",
      "episode 1\n",
      "epsiode 1 training...\n",
      "finish epoch 0 for 0.02894181807835897 minutes\n",
      "finish epoch 1 for 0.030626324812571208 minutes\n",
      "INFO:root:None\n",
      "INFO:root:finish save 8_local_pennylane_100_1_agent_20231120.pt\n",
      "upload: ../../../../braket/input/data/data/8_local_pennylane_100_1_agent_20231120.pt to s3://amazon-braket-us-west-1-002224604296/data/8_local_pennylane_100_1_agent_20231120.pt\n",
      "Code Run Finished\n",
      "e89e7ad2e7970ec8790b593d6c03779f7527588b18fa4815c942bdc67057a02a\n",
      "create job with arn local:job/retrorl-job-local-torch-1700441886\n"
     ]
    }
   ],
   "source": [
    "if train_mode == \"local-instance\":\n",
    "    retro_rl_agent = RetroRLAgent(True, method, **agent_param)\n",
    "    retro_rl_agent.game_job()\n",
    "    print(f\"local instance mode!\")\n",
    "else:\n",
    "    retro_rl_agent = RetroRLAgent(False, method, **agent_param)\n",
    "    retro_rl_agent.game_job()\n",
    "    job_arn = retro_rl_agent.get_job_arn()\n",
    "    print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddcba0ff",
   "metadata": {},
   "source": [
    "#### Step 4: PostProcess Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61e81149-7e6d-40b9-843f-51144384b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results from trained model, let's use the one trained with hybrid job for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d0c62a-7a91-4229-b357-ff96aee05d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8_local_pennylane_100_1_agent_20231120.pt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_save_path = retro_rl_agent.s3_save_path\n",
    "agent_name = s3_save_path.split('/')[-1]\n",
    "data_path = '/'.join(s3_save_path.split('/')[:-1])\n",
    "agent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3fc3d4b-15c9-4523-a5a6-f59815983667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-braket-us-west-1-002224604296/data/8_local_pennylane_100_1_agent_20231119.pt to pathway_files/8_local_pennylane_100_1_agent_20231119.pt\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/8_local_pennylane_100_1_agent_20231120.pt to pathway_files/8_local_pennylane_100_1_agent_20231120.pt\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/8_local_pennylane_100_1_agent_20231119.pickle to pathway_files/8_local_pennylane_100_1_agent_20231119.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/reactions_dictionary.npy to pathway_files/reactions_dictionary.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/ground_truth.npy to pathway_files/ground_truth.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/buyable.npy to pathway_files/buyable.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/Deadend.npy to pathway_files/Deadend.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/256_256_1_agent_20231118.pickle to pathway_files/256_256_1_agent_20231118.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302107/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302107/output/256_256_1_agent_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302450/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302450/output/256_256_1_agent_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302619/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302619/output/256_256_1_agent_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl_model_latest.pickle to pathway_files/retrorl_model_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/smiles to pathway_files/smiles\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302751/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302751/output/256_256_1_agent_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302872/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302872/output/256_256_1_agent_latest.pickle\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/smiles_map.npy to pathway_files/smiles_map.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/target_product.npy to pathway_files/target_product.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/uspto50k.xlsx to pathway_files/uspto50k.xlsx\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/smiles_dictionary.npy to pathway_files/smiles_dictionary.npy\n",
      "download: s3://amazon-braket-us-west-1-002224604296/data/retrorl-job-256-torch-1700302950/output/256_256_1_agent_latest.pickle to pathway_files/retrorl-job-256-torch-1700302950/output/256_256_1_agent_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "!rm -rf pathway_files\n",
    "!mkdir pathway_files\n",
    "!aws s3 sync {data_path} pathway_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cc9aade-ff6a-4e41-a298-6f271c77a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:load data...\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 0.0008044759432474772 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to load agent from pathway_files for pathway function...\n"
     ]
    }
   ],
   "source": [
    "method = \"retro-qrl\"\n",
    "# model_name = '8_local_pennylane_100_1'\n",
    "# retro_rl_model = RetroRLModel.load(\"pathway_files/retrorl_model_latest.pickle\")\n",
    "retro_model = {\"model_name\":model_name}\n",
    "retro_rl_agent = RetroRLAgent(model=False, method=method, load_path=\"pathway_files\", agent_name=agent_name, **agent_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bd3c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'Cc1ccc(S(=O)(=O)O)cc1', 'O=C(O)[C@@H]1CCCN1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'Cc1ccc(S(=O)(=O)O)cc1', 'O=C(O)[C@@H]1CCCN1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  102.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f58dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'O=C(O)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1', 'NCc1ccc(CO)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'O=C(O)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1', 'NCc1ccc(CO)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  3.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'O=C(NCc1ccc(CO)cc1)c1ccccn1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "634c442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1', 'O=C(c1ccccc1)c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'c1ccccc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1', 'O=C(c1ccccc1)c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'c1ccccc1'}\n",
      "The real_cost of Brute force: \n",
      "  2.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "902bfb14",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsQuantumJob\n",
    "from braket.jobs.config import InstanceConfig\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hybridjobs.utility.HybridJobHelpers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66eb11a1",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare parameters for batch evaluation\n",
    "\n",
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100]},\n",
    "        {\"device\": ['local']}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params1\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100,1000]},\n",
    "        {\"device\": ['local']}\n",
    "    ],\n",
    "    \"params2\": [\n",
    "        {\"inputsize\": [256]},\n",
    "        {\"middlesize\": [256,512,1024]},\n",
    "        {\"outputsize\": [1]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# hp = {}\n",
    "# hybrid_job_params = []\n",
    "# parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "# print(f\"parameters for experiments: \\n {hybrid_job_params}\")\n",
    "\n",
    "hybrid_job_params = []\n",
    "for n_qubits in experiments_params['params1'][0][\"n_qubits\"]:\n",
    "    for framework in experiments_params['params1'][1][\"framework\"]:\n",
    "            for layers in experiments_params['params1'][2][\"layers\"]:\n",
    "                for shots in experiments_params['params1'][3][\"shots\"]:\n",
    "                    for device in experiments_params['params1'][4][\"device\"]:\n",
    "                        model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "                        hybrid_job_params.append(model_name)\n",
    "for inputsize in experiments_params['params2'][0][\"inputsize\"]:\n",
    "    for middlesize in experiments_params['params2'][1][\"middlesize\"]:\n",
    "            for outputsize in experiments_params['params2'][2][\"outputsize\"]:                \n",
    "                model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "                hybrid_job_params.append(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avtocost = []\n",
    "model_path = \"./retrorl_model_latest.pickle\"\n",
    "for i in hybrid_job_params:\n",
    "#     model_name = hybrid_job_params[i]\n",
    "    model_name = i\n",
    "    if model_name[0] == \"8\":\n",
    "        method = \"retro-qrl\"\n",
    "    else:\n",
    "        method = \"retro-rl\"\n",
    "    \n",
    "\n",
    "    # train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "    train_mode = \"local-instance\"\n",
    "\n",
    "    data_path = 'data'\n",
    "    agent_param = {}\n",
    "    agent_param[\"data_path\"] = data_path\n",
    "    agent_param[\"train_mode\"] = train_mode\n",
    "    agent_param[\"model_name\"] = model_name\n",
    "    agent_param[\"model_path\"] = model_path\n",
    "\n",
    "    retro_model = None\n",
    "    if train_mode == \"local-instance\":\n",
    "        # get model\n",
    "        retro_rl_model = RetroRLModel.load(model_path)\n",
    "        model_info = retro_rl_model.describe_model()\n",
    "        retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "    retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "    retro_rl_agent.game_job()\n",
    "    avtocost.append(retro_rl_agent.avtocost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the training curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.title('Training curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average cost')\n",
    "for i in range(len(hybrid_job_params)):\n",
    "    plt.plot(range(0,len(avtocost[0])),avtocost[i],label=hybrid_job_params[i])\n",
    "plt.legend(loc = 'upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
