{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199a63d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.1.5 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.1.5)\n",
      "Requirement already satisfied: rdkit==2023.3.1 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2023.3.1)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from rdkit==2023.3.1->-r requirements.txt (line 2)) (9.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/qc_hcls_retrosynthetic_planning_qrl/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa8a212",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2fe146",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from hybridjobs.utility.RetroGateModel import RetroRLModel\n",
    "from hybridjobs.utility.RetroRLAgent import RetroRLAgent\n",
    "from hybridjobs.utility.DataPrepare import Prepare\n",
    "from hybridjobs.utility.BruteForceSearch import expansion, Product, Reaction\n",
    "import time\n",
    "import numpy as np\n",
    "# # Use Braket SDK Cost Tracking to estimate the cost to run this example\n",
    "# from braket.tracking import Tracker\n",
    "# t = Tracker().start()\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e057ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c6b938",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we load the retrosynthesis prediction data for experiment.\n",
    "The [USPTO-50K](https://tdcommons.ai/generation_tasks/retrosyn/#uspto-50k) was \n",
    "put in the repository. We assign the relative \n",
    "path to **raw_path**.\n",
    "The **s3_bucket** and **prefix** are used to store the \n",
    "results. We can use the one created with the \n",
    "cloudformation for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655b6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘datasmiles’: File exists\n",
      "--2023-06-07 02:16:58--  https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
      "Resolving d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)... 13.32.192.18, 13.32.192.42, 13.32.192.102, ...\n",
      "Connecting to d1o8djwwk7diqy.cloudfront.net (d1o8djwwk7diqy.cloudfront.net)|13.32.192.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3841896 (3.7M) [application/zip]\n",
      "Saving to: ‘retrosynthetic-plannin-dataset.zip’\n",
      "\n",
      "retrosynthetic-plan 100%[===================>]   3.66M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-06-07 02:16:58 (85.3 MB/s) - ‘retrosynthetic-plannin-dataset.zip’ saved [3841896/3841896]\n",
      "\n",
      "Archive:  retrosynthetic-plannin-dataset.zip\n",
      "  inflating: retrosynthetic-planning-dataset/buyable.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/target_product.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/reactions_dictionary.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_map.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/ground_truth.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/Deadend.npy  \n",
      "  inflating: retrosynthetic-planning-dataset/uspto50k.xlsx  \n",
      "  inflating: retrosynthetic-planning-dataset/smiles_dictionary.npy  \n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# download dateset\n",
    "!mkdir $data_path\n",
    "!mkdir $data_path\\smiles\n",
    "!wget https://d1o8djwwk7diqy.cloudfront.net/retrosynthetic-plannin-dataset.zip\n",
    "!unzip -o retrosynthetic-plannin-dataset.zip\n",
    "# # windows\n",
    "# !copy retrosynthetic-planning-dataset $data_path\n",
    "# !copy data\\smiles_map.npy  data\\smiles\\smiles_map.npy\n",
    "\n",
    "# linux\n",
    "!cp -r retrosynthetic-planning-dataset/* $data_path\n",
    "!cp data/smiles_map.npy  data/smiles\n",
    "!rm retrosynthetic-plannin-dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24175d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Files are present.\n",
      "INFO:root:All files are generated!\n",
      "INFO:root:File is present.\n"
     ]
    }
   ],
   "source": [
    "# input: predata_uspto-50k.xlsx\n",
    "# output: file1.npy,file2.npy\n",
    "raw_path = 'data/uspto50k.xlsx'\n",
    "prepare = Prepare(raw_path)\n",
    "prepare.generate_files()  # \n",
    "prepare.generate_ground_truth()\n",
    "ground_truth = np.load(prepare.path+'ground_truth.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8431116a",
   "metadata": {},
   "source": [
    "#### Step 2: Build Model\n",
    "\n",
    "In this part, we build the circuit model for retrosynthetic planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c4c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n"
     ]
    }
   ],
   "source": [
    "# initial the RetroRLModel object\n",
    "init_param = {}\n",
    "method = ['retro-rl', 'retro-qrl']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'retro-rl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['inputsize', 'middlesize', 'outputsize']\n",
    "    elif mt == 'retro-qrl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['n_qubits', 'device', 'framework', 'shots', 'layers']\n",
    "    \n",
    "retro_rl_model = RetroRLModel(data=None, method=method, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ea6e07-8dc2-4a44-bb18-285f6b576fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for inputsize:256,middlesize:256,outputsize:1 0.0008102496465047201 min\n",
      "INFO:root:Construct model for inputsize:256,middlesize:512,outputsize:1 1.62045160929362e-05 min\n",
      "INFO:root:Construct model for inputsize:256,middlesize:1024,outputsize:1 2.659161885579427e-05 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-rl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['inputsize'] = [256]\n",
    "model_param[method]['middlesize'] = [256,512,1024]\n",
    "model_param[method]['outputsize'] = [1]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa1f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 0.00023767550786336263 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:2 4.903475443522135e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:3 4.080931345621745e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:1 3.842512766520182e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:2 1.7285346984863281e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane,layers:3 1.5139579772949218e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:1 1.5377998352050782e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:2 1.8795331319173178e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:3 2.0503997802734374e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:1 2.0464261372884116e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:2 1.241763432820638e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane,layers:3 2.6384989420572916e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:1 2.1457672119140625e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:2 1.426537831624349e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:3 7.998943328857421e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:1 6.0677528381347655e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:2 3.6756197611490884e-06 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane,layers:3 1.4980634053548177e-06 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-qrl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['n_qubits'] = [8]\n",
    "model_param[method]['device'] = ['local', 'sv1', 'aspen-m2']\n",
    "model_param[method]['framework'] = ['pennylane']\n",
    "model_param[method]['shots'] = [100,1000]\n",
    "model_param[method]['layers'] = [1,2,3]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9624b3f",
   "metadata": {},
   "source": [
    "We can use the following method to check the properties of \n",
    "model. This way, we can build many models conveniently. \n",
    "After that, we save the model and update the value of \n",
    "**model_path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431a9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {256, 512, 1024}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'aspen-m2', 'local', 'sv1'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {1000, 100}\n",
      "INFO:root:param: layers, value {1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# describe the model parameters\n",
    "model_info = retro_rl_model.describe_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfdc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save retrorl_model_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the nn model for RL and saved it as ./retrorl_model_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = retro_rl_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the nn model for RL and saved it as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b54a25-9ef1-4e2c-a591-def2a1322db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp $model_path $data_path\n",
    "\n",
    "# windows\n",
    "!cp $model_path $data_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb42eb0f",
   "metadata": {},
   "source": [
    "#### Step 3: Learn Retrosynthetic Planning\n",
    "\n",
    "In this part, we use cpu to run classical model for retrosynthetic planning \n",
    "and simulators/NISQ devices to run quantum model for retrosysnthetic planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edad7abf-cdd6-4629-8bc7-8e3b4054b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baba9dfc-ca51-43a1-b7bf-9459f3459402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8537e938-942f-4357-92d8-95af3735de99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run local mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create job with arn arn:aws:braket:us-west-1:002224604296:job/retrorl-job-local-torch-1686104331\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80958946-4527-41f3-9b21-e13c77179a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "inputsize = 256\n",
    "middlesize = 512\n",
    "outputsize = 1\n",
    "\n",
    "model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "method = \"retro-rl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab975431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {256, 512, 1024}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'aspen-m2', 'local', 'sv1'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {1000, 100}\n",
      "INFO:root:param: layers, value {1, 2, 3}\n",
      "INFO:root:load data...\n",
      "INFO:root:model is {'model_name': '256_512_1', 'version': '1686104229', 'nn_model': Model(\n",
      "  (relu): ReLU()\n",
      "  (value_fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (value_fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "game() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m retro_model \u001b[39m=\u001b[39m retro_rl_model\u001b[39m.\u001b[39mget_model(method, model_name)\n\u001b[1;32m     11\u001b[0m retro_rl_agent \u001b[39m=\u001b[39m RetroRLAgent(retro_model, method, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39magent_param)\n\u001b[0;32m---> 12\u001b[0m retro_rl_agent\u001b[39m.\u001b[39;49mgame()\n\u001b[1;32m     13\u001b[0m retro_rl_agent\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mlatest\u001b[39m\u001b[39m\"\u001b[39m, path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: game() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_rl_model = RetroRLModel.load(model_path)\n",
    "model_info = retro_rl_model.describe_model()\n",
    "retro_model = retro_rl_model.get_model(method, model_name)\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game()\n",
    "retro_rl_agent.save(\"latest\", path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_path = retro_rl_agent.save(\"latest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddcba0ff",
   "metadata": {},
   "source": [
    "#### Step 4: PostProcess Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd3c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'Cc1ccc(S(=O)(=O)O)cc1', 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'O=C(O)[C@@H]1CCCN1', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'Cc1ccc(S(=O)(=O)O)cc1', 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC', 'O=C(O)[C@@H]1CCCN1', 'COC=Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1', 'O=[N+]([O-])c1ccc(CO)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  102.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f58dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'N#Cc1ccc(CO)cc1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  3.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'O=C(NCc1ccc(CO)cc1)c1ccccn1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634c442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(c1ccccc1)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(c1ccccc1)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(Cl)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_cost of Brute force: \n",
      "  2.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "902bfb14",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsQuantumJob\n",
    "from braket.jobs.config import InstanceConfig\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utility.HybridJobHelpers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66eb11a1",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare parameters for batch evaluation\n",
    "\n",
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100]},\n",
    "        {\"device\": ['local']}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b67a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"retrosynthetic-planning\"\n",
    "data_path = \"retrosynthetic-planning-data\"\n",
    "suffix_check = [\"txt\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params1\": [\n",
    "        {\"n_qubits\": [8]},\n",
    "        {\"framework\": ['pennylane']},\n",
    "        {\"layers\": [1,2,3]},\n",
    "        {\"shots\": [100,1000]},\n",
    "        {\"device\": ['local']}\n",
    "    ],\n",
    "    \"params2\": [\n",
    "        {\"inputsize\": [256]},\n",
    "        {\"middlesize\": [256,512,1024]},\n",
    "        {\"outputsize\": [1]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# hp = {}\n",
    "# hybrid_job_params = []\n",
    "# parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "# print(f\"parameters for experiments: \\n {hybrid_job_params}\")\n",
    "\n",
    "hybrid_job_params = []\n",
    "for n_qubits in experiments_params['params1'][0][\"n_qubits\"]:\n",
    "    for framework in experiments_params['params1'][1][\"framework\"]:\n",
    "            for layers in experiments_params['params1'][2][\"layers\"]:\n",
    "                for shots in experiments_params['params1'][3][\"shots\"]:\n",
    "                    for device in experiments_params['params1'][4][\"device\"]:\n",
    "                        model_name = \"{}_{}_{}_{}_{}\".format(n_qubits, device, framework, shots, layers)\n",
    "                        hybrid_job_params.append(model_name)\n",
    "for inputsize in experiments_params['params2'][0][\"inputsize\"]:\n",
    "    for middlesize in experiments_params['params2'][1][\"middlesize\"]:\n",
    "            for outputsize in experiments_params['params2'][2][\"outputsize\"]:                \n",
    "                model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "                hybrid_job_params.append(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8593ee25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8_local_pennylane_100_1',\n",
       " '8_local_pennylane_1000_1',\n",
       " '8_local_pennylane_100_2',\n",
       " '8_local_pennylane_1000_2',\n",
       " '8_local_pennylane_100_3',\n",
       " '8_local_pennylane_1000_3',\n",
       " '256_256_1',\n",
       " '256_512_1',\n",
       " '256_1024_1']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avtocost = []\n",
    "for i in hybrid_job_params:\n",
    "    model_name = hybrid_job_params[i]\n",
    "    if model_name[0] == \"8\":\n",
    "        method = \"retro-qrl\"\n",
    "    else:\n",
    "        method = \"retro-rl\"\n",
    "    \n",
    "\n",
    "    # train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "    train_mode = \"local-instance\"\n",
    "\n",
    "    data_path = 'data'\n",
    "    agent_param = {}\n",
    "    agent_param[\"data_path\"] = data_path\n",
    "    agent_param[\"train_mode\"] = train_mode\n",
    "    agent_param[\"model_name\"] = model_name\n",
    "    agent_param[\"model_path\"] = model_path\n",
    "\n",
    "    retro_model = None\n",
    "    if train_mode == \"local-instance\":\n",
    "        # get model\n",
    "        retro_rl_model = RetroRLModel.load(model_path)\n",
    "        model_info = retro_rl_model.describe_model()\n",
    "        retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "    retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "    retro_rl_agent.game_job()\n",
    "    avtocost.append(retro_rl_agent.avtocost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the training curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.title('Training curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average cost')\n",
    "for i in range(len(hybrid_job_params)):\n",
    "    plt.plot(range(0,len(avtocost[0])),avtocost[i],label=hybrid_job_params[i])\n",
    "plt.legend(loc = 'upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc_hcls_retrosynthetic_planning_qrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
