{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0531faa8-9b68-4a7f-833a-b18efbac1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.config import InstanceConfig\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6283c75a-3c8b-4a9e-9fd8-709e7d8da56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "c = copy.deepcopy\n",
    "\n",
    "def obtain_default_bucket(target: str) -> str:\n",
    "    with open(os.path.abspath('../..') + '/.default-setting') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if (line.startswith(target+'=')):\n",
    "                return line.split('=')[1].strip()\n",
    "\n",
    "def get_key(single_dict):\n",
    "    for k in single_dict.keys():\n",
    "        return k\n",
    "\n",
    "def parse_params(params_list, hp, hp_list):\n",
    "    params = params_list[0]\n",
    "    k = get_key(params)\n",
    "    ps = params[k]\n",
    "    for p in ps:\n",
    "        hp[k] = p\n",
    "        if len(params_list) == 1:\n",
    "            hp_list.append(c(hp))\n",
    "        else:\n",
    "            parse_params(params_list[1:], hp, hp_list)\n",
    "\n",
    "def get_quantum_device(device_name):\n",
    "    device_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\"\n",
    "    try:\n",
    "        device = AwsDevice.get_devices(names=[device_name])\n",
    "        device_arn = device[0].arn\n",
    "    except Exception as e:\n",
    "        print(f\"fail to get {device_name}: {e}, use sv1 instead\")\n",
    "    return device_arn\n",
    "\n",
    "def upload_data(dir_name, aws_session=AwsSession()):\n",
    "    stream_s3_uri = aws_session.construct_s3_uri(obtain_default_bucket(\"bucketName\"), dir_name)\n",
    "    return_path = None\n",
    "    \n",
    "    def _check_upload(file_name, check_list):\n",
    "        file_end = file_name.split('.')[-1]\n",
    "        if file_end in check_list:\n",
    "            path = f\"{stream_s3_uri}/\" + file_name.split('/')[-1]\n",
    "            aws_session.upload_to_s3(file_name, path)\n",
    "            \n",
    "    if os.path.isdir(dir_name):\n",
    "        dir_list = os.listdir(dir_name)\n",
    "        for file_name in dir_list:\n",
    "            _check_upload(os.path.join(dir_name,file_name), ['mol2'])\n",
    "        return_path = stream_s3_uri\n",
    "    else:\n",
    "        _check_upload(file_name, ['mol2'])\n",
    "        single_file_name = file_name.split('/')[-1]\n",
    "        return_path = f\"{stream_s3_uri}/{single_file_name}\"\n",
    "        \n",
    "    return return_path\n",
    "\n",
    "def queue_check(jobs):\n",
    "    queue_count = 0\n",
    "    running_count = 0\n",
    "    check_pass = True\n",
    "    for job in jobs:\n",
    "        # print(f\"job state {job.state()}\")\n",
    "        if job.state() == \"QUEUED\":\n",
    "            queue_count = queue_count + 1\n",
    "        if job.state() == \"RUNNING\":\n",
    "            running_count = running_count + 1\n",
    "        if queue_count + running_count >= 5:\n",
    "            check_pass = False\n",
    "    \n",
    "    print(f\"queue_count {queue_count}, running_count {running_count}\")\n",
    "    \n",
    "    return check_pass\n",
    "\n",
    "def get_result(result):\n",
    "    return [result[\"hypermeter\"][\"D\"], result[\"hypermeter\"][\"M\"], int(result[\"hypermeter\"][\"D\"])*int(result[\"hypermeter\"][\"M\"]), result[\"time\"]]\n",
    "\n",
    "def display_results(results, experiments_params):\n",
    "    sorted_results = {}\n",
    "    for device in experiments_params[\"params\"][3][\"device\"]:\n",
    "        sorted_results[str(device)] = []\n",
    "    max_offset = 10\n",
    "    for result in results:\n",
    "        d = int(result[\"hypermeter\"][\"D\"])\n",
    "        m = int(result[\"hypermeter\"][\"M\"])\n",
    "        dm = (d * m)<<10 + d\n",
    "        device = result[\"hypermeter\"][\"device\"]\n",
    "        \n",
    "        if len(sorted_results[device]) == 0:\n",
    "            sorted_results[device].append(get_result(result))\n",
    "            continue\n",
    "        \n",
    "        last_idx = 0\n",
    "        for idx, sorted_result in enumerate(sorted_results[device]):\n",
    "            sorted_d = int(sorted_result[0])\n",
    "            sorted_m = int(sorted_result[1])\n",
    "            sorted_dm = (sorted_d * sorted_m)<<max_offset + sorted_d\n",
    "            \n",
    "            last_sorted_d = int(sorted_results[device][last_idx][0])\n",
    "            last_sorted_m = int(sorted_results[device][last_idx][1])\n",
    "            last_sorted_dm = (last_sorted_d * last_sorted_m)<<max_offset + last_sorted_d\n",
    "            \n",
    "            if last_sorted_dm < dm and dm < sorted_dm:\n",
    "                sorted_results[device].insert(idx,get_result(result))\n",
    "                break\n",
    "            elif dm < last_sorted_dm and idx == 0:\n",
    "                sorted_results[device].insert(last_idx,get_result(result))\n",
    "                break\n",
    "            elif dm > sorted_dm and idx == len(sorted_results[device])-1:\n",
    "                sorted_results[device].insert(idx+1,get_result(result))\n",
    "            \n",
    "            last_idx = idx\n",
    "    # print(f\"sorted result {sorted_results}\")\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bff851-8ffe-4a26-82cf-44cc1c7b51cc",
   "metadata": {},
   "source": [
    "# Step 1: Prepare parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f632b-466b-4f96-96e8-e57f3e18bba2",
   "metadata": {},
   "source": [
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2cc57f-b61f-48ef-8d7b-580f47f66d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'M': 1, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 1, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 2, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 2, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 3, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 3, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 4, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 4, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 5, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 5, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 6, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 6, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"molecular-unfolding\"\n",
    "data_path = \"molecular-unfolding-data\"\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"M\": [1,2,3,4,5,6]},\n",
    "        {\"D\": [8]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"},{\"qc\": \"null\", \"cc\": \"ml.m5.4xlarge\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2062d7b-b958-4c35-bf9f-202480d4d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-us-east-1-002224604296/molecular-unfolding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path)\n",
    "print(f\"upload data to s3 path: {s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca29ed-d4e0-4cb2-8c2e-73e0962caea4",
   "metadata": {},
   "source": [
    "# Step 2: Prepare image for experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79337ff4-4617-4b0c-b109-0d3ef08148ae",
   "metadata": {},
   "source": [
    "In this part, we use the following code to prepare the image for experiment. For the first run, \n",
    "please run build_and_push.sh to create the image. For future experiments, avoid running\n",
    "build_and_push.sh unless you want to rebuild the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320b1c6b-c575-4d41-a69a-cde747d903cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 002224604296 in region us-east-1: 002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-molecular-unfolding-jobs:latest\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "!sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c7a433-6518-4f13-8b0f-4abd35b4c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job info will be saved in molecular-unfolding-hybrid-jobs.json\n"
     ]
    }
   ],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_jobs_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099242e-ae41-482a-969b-ccd1d529a21c",
   "metadata": {},
   "source": [
    "# Step 3: Launch Amazon Braket Hybrid Jobs for experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3229c-bec9-40fa-b577-baf75adea418",
   "metadata": {},
   "source": [
    "In this part, we use the following code to launch the same number of hybrid jobs as the sets of parameters for this experiments.\n",
    "When the number of jobs exceeds 5, this thread will wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d52f18-791a-4943-abaf-1a9911815709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 1, D 8 and device ml-m5-large\n",
      "queue_count 1, running_count 0\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 1, D 8 and device ml-m5-4large\n",
      "queue_count 1, running_count 1\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 2, D 8 and device ml-m5-large\n",
      "queue_count 1, running_count 2\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 2, D 8 and device ml-m5-4large\n",
      "queue_count 1, running_count 3\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 3, D 8 and device ml-m5-large\n",
      "queue_count 1, running_count 4\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 4\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 3, D 8 and device ml-m5-4large\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 2\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 4, D 8 and device ml-m5-large\n",
      "queue_count 1, running_count 2\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 4, D 8 and device ml-m5-4large\n",
      "queue_count 2, running_count 2\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 5, D 8 and device ml-m5-large\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 3, running_count 2\n",
      "queue_count 2, running_count 2\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 5, D 8 and device ml-m5-4large\n",
      "queue_count 3, running_count 3\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 4\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 6, D 8 and device ml-m5-large\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 4\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 6, D 8 and device ml-m5-4large\n",
      "queue_count 0, running_count 4\n",
      "Finish launch all the hybrid jobs and save all the files\n"
     ]
    }
   ],
   "source": [
    "# Long runnning cell due to Burst rate of CreateJob requests < 5 RPS\n",
    "# sudo apt-get install python-prctl at first\n",
    "# https://stackoverflow.com/questions/34361035/python-thread-name-doesnt-show-up-on-ps-or-htop\n",
    "from threading import Thread\n",
    "import threading\n",
    "import setproctitle\n",
    "\n",
    "def launch_hybrid_jobs(hybrid_job_params=hybrid_job_params, hybrid_jobs_json=hybrid_jobs_json):\n",
    "    setproctitle.setproctitle(threading.current_thread().name)\n",
    "    # parse evaluation parameters and trigger hybrid jobs:\n",
    "    jobs = []\n",
    "    names = []\n",
    "\n",
    "    job_name = f\"{experiment_name}-job\"\n",
    "\n",
    "    # from braket.jobs.local import LocalQuantumJob\n",
    "\n",
    "    for job_param in hybrid_job_params:\n",
    "        M = job_param['M']\n",
    "        D = job_param['D']\n",
    "        quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "        classical_device = job_param['device']['cc']\n",
    "\n",
    "        device_name = classical_device.replace(\".\",\"-\")\n",
    "        device_name = device_name.replace(\"x\",\"\")\n",
    "        \n",
    "        name = f\"{experiment_name}-M-{M}-D-{D}-{device_name}\" + str(int(time.time()))\n",
    "\n",
    "        tmp_job = AwsQuantumJob.create(\n",
    "            device=quantum_device,\n",
    "            source_module=f\"{experiment_name}\",\n",
    "            entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "            job_name=name,\n",
    "            hyperparameters=job_param,\n",
    "            input_data=s3_path,\n",
    "            instance_config=InstanceConfig(instanceType=classical_device),\n",
    "            image_uri=image_uri,\n",
    "            wait_until_complete=False,\n",
    "        )\n",
    "        \n",
    "        print(f\"Finish create {experiment_name} with M {M}, D {D} and device {device_name}\")\n",
    "\n",
    "        jobs.append(tmp_job)\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "        while not queue_check(jobs):\n",
    "            time.sleep(5)\n",
    "    jobs_arn = []\n",
    "\n",
    "    for job in jobs:\n",
    "        jobs_arn.append(job.arn)\n",
    "\n",
    "    jobs_states = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"hybrid-jobs-arn\": jobs_arn,\n",
    "        \"names\": names\n",
    "    }\n",
    "    \n",
    "    # save hybrid job arn for further analysis\n",
    "    json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "    with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    print(f\"Finish launch all the hybrid jobs and save all the files\")\n",
    "\n",
    "t = Thread(target=launch_hybrid_jobs, name=\"launch-hybrid-job\", daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216bd344-121f-4e2d-8b35-f64efd298567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu     85131  0.0  1.3 1667824 438060 ?      Ssl  Jan05   0:35 launch-hybrid-job\n",
      "ubuntu     90748  0.0  1.5 1864064 491840 ?      Ssl  Jan06   1:49 launch-hybrid-job\n",
      "ubuntu    138118  0.0  1.6 1754604 523720 ?      Ssl  Jan10   0:22 launch-hybrid-job\n",
      "ubuntu    145298  0.0  1.6 1823156 526432 ?      Rsl  Jan11   0:18 launch-hybrid-job\n",
      "ubuntu    157651  0.0  0.0   8748  3444 pts/0    Ss+  11:48   0:00 /bin/bash -c ps -aux | grep launch-hybrid-job\n",
      "ubuntu    157653  0.0  0.0   8176   664 pts/0    S+   11:48   0:00 grep launch-hybrid-job\n"
     ]
    }
   ],
   "source": [
    "# run the following scripts to check the created threads\n",
    "!ps -aux | grep launch-hybrid-job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f16e7-8959-433f-9d1b-cc001cd25c2f",
   "metadata": {},
   "source": [
    "# Step 4: Jobs finish and visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2a13b-4d69-4c35-8149-b6b00a0969ef",
   "metadata": {},
   "source": [
    "Please use the following code to check the status of hybrid jobs. The status of hybrid jobs can also be checked in the Amazon Braket console. Optionally, if the email if input when deploying the solution, emails will be sent at the same number of hybrid jobs once \n",
    "the status of jobs changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a643773a-ecaa-4af5-a7eb-ed276f7930b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job molecular-unfolding-M-1-D-8-ml-m5-large1673608692 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-1-D-8-ml-m5-4large1673608697 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-2-D-8-ml-m5-large1673608702 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-2-D-8-ml-m5-4large1673608706 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-3-D-8-ml-m5-large1673608711 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-3-D-8-ml-m5-4large1673608843 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-4-D-8-ml-m5-large1673608856 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-4-D-8-ml-m5-4large1673608862 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-5-D-8-ml-m5-large1673608868 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-5-D-8-ml-m5-4large1673608942 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-6-D-8-ml-m5-large1673609027 is : COMPLETED\n",
      "the state of job molecular-unfolding-M-6-D-8-ml-m5-4large1673609141 is : COMPLETED\n",
      "all jobs completed\n"
     ]
    }
   ],
   "source": [
    "# run the following code to test whether all the jobs finish\n",
    "results = []\n",
    "if os.path.exists(hybrid_jobs_json):\n",
    "    # recover hybrid jobs and show result\n",
    "    jobs_states_load = None\n",
    "    with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "        jobs_states_load = json.load(outfile)\n",
    "\n",
    "    completed_jobs_arn = set()\n",
    "\n",
    "    for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "        current_job = AwsQuantumJob(job_arn)\n",
    "        print(f\"the state of job {job_name} is : {current_job.state()}\")\n",
    "        if current_job.state() == 'COMPLETED':\n",
    "            completed_jobs_arn.update({job_arn})\n",
    "\n",
    "    whole_jobs_num = len(jobs_states_load[\"names\"])\n",
    "\n",
    "    results = None\n",
    "    if len(completed_jobs_arn) == whole_jobs_num:\n",
    "        print(f\"all jobs completed\")\n",
    "        results = []\n",
    "        for job_arn in completed_jobs_arn:\n",
    "            current_job = AwsQuantumJob(job_arn)\n",
    "            results.append(current_job.result())\n",
    "        # display results\n",
    "        results = display_results(results, experiments_params)\n",
    "else:\n",
    "    print(f\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9924cb0d-be27-49be-a8f0-e466648e269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-450bcfe8cf294508909bcec0f5a4f1f9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-450bcfe8cf294508909bcec0f5a4f1f9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-450bcfe8cf294508909bcec0f5a4f1f9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-eb1e6cf47b0faa599af05d8d9e5d4d1d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Device\", \"type\": \"nominal\"}, \"x\": {\"field\": \"DxM\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Time to Solution\", \"type\": \"quantitative\"}}, \"height\": 600, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Molecular unfolding experiments\", \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-eb1e6cf47b0faa599af05d8d9e5d4d1d\": [{\"DxM\": 8, \"Time to Solution\": 2.6319169998168945, \"Device\": \"ml.m5.large\"}, {\"DxM\": 16, \"Time to Solution\": 3.6955196857452393, \"Device\": \"ml.m5.large\"}, {\"DxM\": 24, \"Time to Solution\": 21.67833399772644, \"Device\": \"ml.m5.large\"}, {\"DxM\": 32, \"Time to Solution\": 64.4586923122406, \"Device\": \"ml.m5.large\"}, {\"DxM\": 40, \"Time to Solution\": 333.8167448043823, \"Device\": \"ml.m5.large\"}, {\"DxM\": 48, \"Time to Solution\": 568.3858327865601, \"Device\": \"ml.m5.large\"}, {\"DxM\": 8, \"Time to Solution\": 2.577850818634033, \"Device\": \"ml.m5.4xlarge\"}, {\"DxM\": 16, \"Time to Solution\": 3.620022773742676, \"Device\": \"ml.m5.4xlarge\"}, {\"DxM\": 24, \"Time to Solution\": 21.106844902038574, \"Device\": \"ml.m5.4xlarge\"}, {\"DxM\": 32, \"Time to Solution\": 62.45652174949646, \"Device\": \"ml.m5.4xlarge\"}, {\"DxM\": 40, \"Time to Solution\": 295.5421953201294, \"Device\": \"ml.m5.4xlarge\"}, {\"DxM\": 48, \"Time to Solution\": 554.2115716934204, \"Device\": \"ml.m5.4xlarge\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_result = {}\n",
    "device_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,vs in results.items():\n",
    "    k = k.replace(\"\\'\",\"\\\"\")\n",
    "    dict_k = json.loads(k)\n",
    "    device_name = None\n",
    "    if dict_k['qc'] == 'null':\n",
    "        device_name = dict_k['cc']\n",
    "    else:\n",
    "        device_name = dict_k['qc']\n",
    "    for v in vs:\n",
    "        device_list.append(device_name)\n",
    "        x_list.append(v[2])\n",
    "        y_list.append(v[3])\n",
    "source = pd.DataFrame({\n",
    "    \"DxM\": np.array(x_list),\n",
    "    \"Time to Solution\": np.array(y_list),\n",
    "    \"Device\": np.array(device_list),\n",
    "})\n",
    "\n",
    "alt.Chart(source).mark_line(point = True).encode(\n",
    "    x='DxM',\n",
    "    y='Time to Solution',\n",
    "    color='Device',\n",
    ").properties(\n",
    "    title = \"Molecular unfolding experiments\",\n",
    "    width = 700,\n",
    "    height = 600,\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
