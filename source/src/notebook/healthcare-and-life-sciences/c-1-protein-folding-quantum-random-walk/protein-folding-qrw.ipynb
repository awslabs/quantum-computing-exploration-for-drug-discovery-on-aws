{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==1.4.0 (from -r requirements.txt (line 1))\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting altair==4.2.2 (from -r requirements.txt (line 2))\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Collecting amazon-braket-default-simulator==1.11.5.post0 (from -r requirements.txt (line 3))\n",
      "  Using cached amazon_braket_default_simulator-1.11.5.post0-py3-none-any.whl (206 kB)\n",
      "Collecting amazon-braket-schemas==1.14.1.post0 (from -r requirements.txt (line 4))\n",
      "  Using cached amazon_braket_schemas-1.14.1.post0-py3-none-any.whl (109 kB)\n",
      "Collecting amazon-braket-sdk==1.35.5 (from -r requirements.txt (line 5))\n",
      "  Using cached amazon_braket_sdk-1.35.5-py3-none-any.whl (245 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.2 (from -r requirements.txt (line 6))\n",
      "  Using cached antlr4-python3-runtime-4.9.2.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anyio==3.6.2 (from -r requirements.txt (line 7))\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting appdirs==1.4.4 (from -r requirements.txt (line 8))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting argon2-cffi==21.3.0 (from -r requirements.txt (line 9))\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from -r requirements.txt (line 10))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting astor==0.8.1 (from -r requirements.txt (line 11))\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting async-generator==1.10 (from -r requirements.txt (line 12))\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting attrs==22.1.0 (from -r requirements.txt (line 13))\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting Babel==2.11.0 (from -r requirements.txt (line 14))\n",
      "  Using cached Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
      "Requirement already satisfied: backcall==0.2.0 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (0.2.0)\n",
      "Collecting backoff==2.2.1 (from -r requirements.txt (line 16))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting beautifulsoup4==4.11.2 (from -r requirements.txt (line 17))\n",
      "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "Collecting bleach==4.1.0 (from -r requirements.txt (line 18))\n",
      "  Using cached bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting bokeh==2.3.3 (from -r requirements.txt (line 19))\n",
      "  Using cached bokeh-2.3.3.tar.gz (10.7 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boltons==23.0.0 (from -r requirements.txt (line 20))\n",
      "  Using cached boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
      "Collecting boto3==1.23.10 (from -r requirements.txt (line 21))\n",
      "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Collecting botocore==1.26.10 (from -r requirements.txt (line 22))\n",
      "  Using cached botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
      "Collecting cached-property==1.5.2 (from -r requirements.txt (line 23))\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting certifi==2022.12.7 (from -r requirements.txt (line 24))\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting cffi==1.15.1 (from -r requirements.txt (line 25))\n",
      "  Using cached cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Collecting charset-normalizer==2.0.12 (from -r requirements.txt (line 26))\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting contextvars==2.4 (from -r requirements.txt (line 27))\n",
      "  Using cached contextvars-2.4.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cryptography==39.0.0 (from -r requirements.txt (line 28))\n",
      "  Using cached cryptography-39.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
      "Collecting cycler==0.11.0 (from -r requirements.txt (line 29))\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting debugpy==1.6.6 (from -r requirements.txt (line 30))\n",
      "  Using cached debugpy-1.6.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 31)) (5.1.1)\n",
      "Collecting defusedxml==0.7.1 (from -r requirements.txt (line 32))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting dill==0.3.4 (from -r requirements.txt (line 33))\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting dlx==1.0.4 (from -r requirements.txt (line 34))\n",
      "  Using cached dlx-1.0.4.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docplex==2.25.236 (from -r requirements.txt (line 35))\n",
      "  Using cached docplex-2.25.236.tar.gz (633 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: entrypoints==0.4 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 36)) (0.4)\n",
      "Collecting fastdtw==0.3.4 (from -r requirements.txt (line 37))\n",
      "  Using cached fastdtw-0.3.4.tar.gz (133 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastjsonschema==2.16.2 (from -r requirements.txt (line 38))\n",
      "  Using cached fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
      "Collecting gast==0.2.2 (from -r requirements.txt (line 39))\n",
      "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-pasta==0.2.0 (from -r requirements.txt (line 40))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio==1.48.2 (from -r requirements.txt (line 41))\n",
      "  Using cached grpcio-1.48.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting h5py==2.10.0 (from -r requirements.txt (line 42))\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting idna==3.4 (from -r requirements.txt (line 43))\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting immutables==0.19 (from -r requirements.txt (line 44))\n",
      "  Using cached immutables-0.19-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Collecting importlib-metadata==4.8.3 (from -r requirements.txt (line 45))\n",
      "  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources==5.12.0 (from -r requirements.txt (line 46))\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting inflection==0.5.1 (from -r requirements.txt (line 47))\n",
      "  Using cached inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting install==1.3.5 (from -r requirements.txt (line 48))\n",
      "  Using cached install-1.3.5-py3-none-any.whl (3.2 kB)\n",
      "Collecting ipykernel==5.5.6 (from -r requirements.txt (line 49))\n",
      "  Using cached ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
      "Collecting ipython==7.16.3 (from -r requirements.txt (line 50))\n",
      "  Using cached ipython-7.16.3-py3-none-any.whl (783 kB)\n",
      "Collecting ipython-genutils==0.2.0 (from -r requirements.txt (line 51))\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jedi==0.17.2 (from -r requirements.txt (line 52))\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting Jinja2==3.0.3 (from -r requirements.txt (line 53))\n",
      "  Using cached Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting jmespath==0.10.0 (from -r requirements.txt (line 54))\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting joblib==1.1.1 (from -r requirements.txt (line 55))\n",
      "  Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "Collecting json5==0.9.11 (from -r requirements.txt (line 56))\n",
      "  Using cached json5-0.9.11-py2.py3-none-any.whl (19 kB)\n",
      "Collecting jsonschema==3.2.0 (from -r requirements.txt (line 57))\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting jupyter-client==7.1.2 (from -r requirements.txt (line 58))\n",
      "  Using cached jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
      "Collecting jupyter-core==4.9.2 (from -r requirements.txt (line 59))\n",
      "  Using cached jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
      "Collecting jupyter-server==1.13.1 (from -r requirements.txt (line 60))\n",
      "  Using cached jupyter_server-1.13.1-py3-none-any.whl (396 kB)\n",
      "Collecting jupyterlab==3.2.9 (from -r requirements.txt (line 61))\n",
      "  Using cached jupyterlab-3.2.9-py3-none-any.whl (8.5 MB)\n",
      "Collecting jupyterlab-pygments==0.1.2 (from -r requirements.txt (line 62))\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting jupyterlab-server==2.10.3 (from -r requirements.txt (line 63))\n",
      "  Using cached jupyterlab_server-2.10.3-py3-none-any.whl (61 kB)\n",
      "Collecting Keras==2.0.8 (from -r requirements.txt (line 64))\n",
      "  Using cached Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
      "Collecting Keras-Applications==1.0.8 (from -r requirements.txt (line 65))\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting Keras-Preprocessing==1.1.2 (from -r requirements.txt (line 66))\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting kiwisolver==1.3.1 (from -r requirements.txt (line 67))\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting lxml==4.9.2 (from -r requirements.txt (line 68))\n",
      "  Using cached lxml-4.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n",
      "Collecting Markdown==3.3.7 (from -r requirements.txt (line 69))\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting MarkupSafe==2.0.1 (from -r requirements.txt (line 70))\n",
      "  Using cached MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
      "Collecting matplotlib==3.3.4 (from -r requirements.txt (line 71))\n",
      "  Using cached matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 72)) (0.1.6)\n",
      "Collecting mistune==0.8.4 (from -r requirements.txt (line 73))\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting more-itertools==8.14.0 (from -r requirements.txt (line 74))\n",
      "  Using cached more_itertools-8.14.0-py3-none-any.whl (52 kB)\n",
      "Collecting mpmath==1.2.1 (from -r requirements.txt (line 75))\n",
      "  Using cached mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "Collecting multitasking==0.0.11 (from -r requirements.txt (line 76))\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 77))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting nbclassic==0.3.5 (from -r requirements.txt (line 78))\n",
      "  Using cached nbclassic-0.3.5-py3-none-any.whl (25 kB)\n",
      "Collecting nbclient==0.5.9 (from -r requirements.txt (line 79))\n",
      "  Using cached nbclient-0.5.9-py3-none-any.whl (69 kB)\n",
      "Collecting nbconvert==6.0.7 (from -r requirements.txt (line 80))\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting nbformat==5.1.3 (from -r requirements.txt (line 81))\n",
      "  Using cached nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Collecting nest-asyncio==1.5.6 (from -r requirements.txt (line 82))\n",
      "  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting networkx==2.6.3 (from -r requirements.txt (line 83))\n",
      "  Using cached networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "Collecting notebook==6.4.10 (from -r requirements.txt (line 84))\n",
      "  Using cached notebook-6.4.10-py3-none-any.whl (9.9 MB)\n",
      "Collecting notebook_shim==0.2.2 (from -r requirements.txt (line 85))\n",
      "  Using cached notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
      "Collecting ntlm-auth==1.5.0 (from -r requirements.txt (line 86))\n",
      "  Using cached ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting numpy==1.21.6 (from -r requirements.txt (line 87))\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openpulse==0.4.1 (from -r requirements.txt (line 88))\n",
      "  Downloading openpulse-0.4.1-py3-none-any.whl (376 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.3/376.3 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openqasm3==0.4.0 (from -r requirements.txt (line 89))\n",
      "  Downloading openqasm3-0.4.0-py3-none-any.whl (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.3/385.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum==3.3.0 (from -r requirements.txt (line 90))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting oqpy==0.1.2 (from -r requirements.txt (line 91))\n",
      "  Downloading oqpy-0.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting packaging==21.3 (from -r requirements.txt (line 92))\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.1.5 (from -r requirements.txt (line 93))\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandocfilters==1.5.0 (from -r requirements.txt (line 94))\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting parso==0.7.1 (from -r requirements.txt (line 95))\n",
      "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pbr==5.11.1 (from -r requirements.txt (line 96))\n",
      "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pexpect==4.8.0 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 97)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 98)) (0.7.5)\n",
      "Collecting Pillow==8.4.0 (from -r requirements.txt (line 99))\n",
      "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pip==23.0.1 (from -r requirements.txt (line 100))\n",
      "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pkgutil_resolve_name==1.3.10 (from -r requirements.txt (line 101))\n",
      "  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting ply==3.11 (from -r requirements.txt (line 102))\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prometheus-client==0.16.0 (from -r requirements.txt (line 103))\n",
      "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prompt-toolkit==3.0.36 (from -r requirements.txt (line 104))\n",
      "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf==3.19.6 (from -r requirements.txt (line 105))\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting psutil==5.9.4 (from -r requirements.txt (line 106))\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess==0.7.0 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 107)) (0.7.0)\n",
      "Collecting pyasn1==0.4.8 (from -r requirements.txt (line 108))\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser==2.21 (from -r requirements.txt (line 109))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting pydantic==1.10.2 (from -r requirements.txt (line 110))\n",
      "  Downloading pydantic-1.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pygments==2.14.0 (from -r requirements.txt (line 111))\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing==3.0.9 (from -r requirements.txt (line 112))\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyrsistent==0.18.0 (from -r requirements.txt (line 113))\n",
      "  Downloading pyrsistent-0.18.0-cp37-cp37m-manylinux1_x86_64.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-constraint==1.4.0 (from -r requirements.txt (line 114))\n",
      "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 115)) (2.8.2)\n",
      "Collecting pytz==2022.6 (from -r requirements.txt (line 116))\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML==6.0 (from -r requirements.txt (line 117))\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyzmq==25.0.0 (from -r requirements.txt (line 118))\n",
      "  Downloading pyzmq-25.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting qiskit==0.34.2 (from -r requirements.txt (line 119))\n",
      "  Downloading qiskit-0.34.2.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting qiskit-aer==0.10.3 (from -r requirements.txt (line 120))\n",
      "  Downloading qiskit_aer-0.10.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting qiskit-aqua==0.9.5 (from -r requirements.txt (line 121))\n",
      "  Downloading qiskit_aqua-0.9.5-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qiskit-ibmq-provider==0.18.3 (from -r requirements.txt (line 122))\n",
      "  Downloading qiskit_ibmq_provider-0.18.3-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qiskit-ignis==0.7.0 (from -r requirements.txt (line 123))\n",
      "  Downloading qiskit_ignis-0.7.0-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting qiskit-terra==0.19.2 (from -r requirements.txt (line 124))\n",
      "  Downloading qiskit_terra-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting Quandl==3.7.0 (from -r requirements.txt (line 125))\n",
      "  Downloading Quandl-3.7.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting requests==2.27.1 (from -r requirements.txt (line 126))\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-ntlm==1.1.0 (from -r requirements.txt (line 127))\n",
      "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
      "Collecting retworkx==0.11.0 (from -r requirements.txt (line 128))\n",
      "  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer==0.5.2 (from -r requirements.txt (line 129))\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==0.24.2 (from -r requirements.txt (line 130))\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.5.4 (from -r requirements.txt (line 131))\n",
      "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/25.9 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Send2Trash==1.8.0 (from -r requirements.txt (line 132))\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting setproctitle==1.3.2 (from -r requirements.txt (line 133))\n",
      "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting setuptools==67.6.0 (from -r requirements.txt (line 134))\n",
      "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 135)) (1.16.0)\n",
      "Collecting sniffio==1.2.0 (from -r requirements.txt (line 136))\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting soupsieve==2.4 (from -r requirements.txt (line 137))\n",
      "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
      "Collecting stevedore==3.5.2 (from -r requirements.txt (line 138))\n",
      "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting symengine==0.8.1 (from -r requirements.txt (line 139))\n",
      "  Downloading symengine-0.8.1-cp37-cp37m-manylinux2010_x86_64.whl (38.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting sympy==1.9 (from -r requirements.txt (line 140))\n",
      "  Downloading sympy-1.9-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard==1.15.0 (from -r requirements.txt (line 141))\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow==1.15.0 (from -r requirements.txt (line 142))\n",
      "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 MB\u001b[0m \u001b[31m950.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator==1.15.1 (from -r requirements.txt (line 143))\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.4/503.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor==1.1.0 (from -r requirements.txt (line 144))\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting terminado==0.12.1 (from -r requirements.txt (line 145))\n",
      "  Downloading terminado-0.12.1-py3-none-any.whl (15 kB)\n",
      "Collecting testpath==0.6.0 (from -r requirements.txt (line 146))\n",
      "  Downloading testpath-0.6.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl==3.1.0 (from -r requirements.txt (line 147))\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting tinycss2==1.2.1 (from -r requirements.txt (line 148))\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting toolz==0.12.0 (from -r requirements.txt (line 149))\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Collecting tornado==6.1 (from -r requirements.txt (line 150))\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.5/428.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting traitlets==4.3.3 (from -r requirements.txt (line 151))\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tweedledum==1.1.1 (from -r requirements.txt (line 152))\n",
      "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.8/943.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing_extensions==4.1.1 (from -r requirements.txt (line 153))\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting urllib3==1.26.14 (from -r requirements.txt (line 154))\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in /home/ec2-user/anaconda3/envs/qc_hcls_python37/lib/python3.7/site-packages (from -r requirements.txt (line 155)) (0.2.6)\n",
      "Collecting webencodings==0.5.1 (from -r requirements.txt (line 156))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting websocket-client==1.3.1 (from -r requirements.txt (line 157))\n",
      "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Werkzeug==2.0.3 (from -r requirements.txt (line 158))\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.2/289.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wheel==0.38.4 (from -r requirements.txt (line 159))\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting wrapt==1.14.1 (from -r requirements.txt (line 160))\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m384.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yfinance==0.1.87 (from -r requirements.txt (line 161))\n",
      "  Downloading yfinance-0.1.87-py2.py3-none-any.whl (29 kB)\n",
      "Collecting zipp==3.6.0 (from -r requirements.txt (line 162))\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, bokeh, contextvars, dlx, docplex, fastdtw, gast, python-constraint, qiskit, termcolor\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.2-py3-none-any.whl size=144548 sha256=5c7fca44d42d0e344fd493249fc9c568fb785eca8ad339e39e5ee00818566aa6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/14/4c/18/1dbbc9875a2547d2063400ea9f404da4af3331965a71061029\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.3.3-py3-none-any.whl size=11342764 sha256=ba39d669dc91482d5528cf0aadbf565831b12d6320dea0768f6f31fd83980a8f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/57/e3/79/051e58e8a3d9076de99bdd7d68d463289e28c18329933984ff\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=4719fef5986334f0af1cd72e0bb94ad863f39091a3826ea4589ec9ea4fe14bae\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
      "  Building wheel for dlx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlx: filename=dlx-1.0.4-py3-none-any.whl size=5703 sha256=49a44853b1ccc637ab0541ea3b6ffb780a1f36a452ddfabe6a1e8da974a4e686\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/78/55/c8/dc61e772445a566b7608a476d151e9dcaf4e092b01b0c4bc3c\n",
      "  Building wheel for docplex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docplex: filename=docplex-2.25.236-py3-none-any.whl size=671349 sha256=4cf8363e0ce0bdd4300a35769f588db92e8ec4701a60b628d8d68e5524f6c8b5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/26/6b/d2/53c14b3360c0b9014b1d8592f9b4488c42fd36f5538cd589b4\n",
      "  Building wheel for fastdtw (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastdtw: filename=fastdtw-0.3.4-py3-none-any.whl size=3565 sha256=3757242a02eb9b7b93faf74043cb9748493faaf5272ade04c75cd529c41b5c81\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a2/da/8c/2d1b9b233595056f05e59156bb555f7277b88beb385605de16\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7538 sha256=0136e3cbafb826e85ff6cdc48d85c094e34ae9bddd2c06e09ddd09b498721f03\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for python-constraint (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24058 sha256=1009ac622e9ea32d2167cca38e83ff6c033750b046c2f4ef3f242594491389c1\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
      "  Building wheel for qiskit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for qiskit: filename=qiskit-0.34.2-py3-none-any.whl size=11780 sha256=cf163afff0674bd35d315ccbff347156b6c7d222bd15a4fe0d7374f5b0402fb4\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/62/77/65/cda6eedfdd2a525bd3f479a4386930ae3088a1eb01f8c944ed\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=875b1f2f94698c20c8b8914d826de67b7a5d94f6554bbbf74d9cdbe568e1d875\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built antlr4-python3-runtime bokeh contextvars dlx docplex fastdtw gast python-constraint qiskit termcolor\n",
      "Installing collected packages: webencodings, termcolor, tensorflow-estimator, Send2Trash, pytz, python-constraint, pyasn1, ply, openqasm3, multitasking, mpmath, mistune, json5, ipython-genutils, fastjsonschema, dlx, cached-property, boltons, appdirs, antlr4-python3-runtime, zipp, wrapt, wheel, Werkzeug, websocket-client, urllib3, typing_extensions, tweedledum, traitlets, tornado, toolz, tinycss2, threadpoolctl, testpath, sympy, symengine, soupsieve, sniffio, setuptools, setproctitle, pyzmq, PyYAML, pyrsistent, pyparsing, Pygments, pycparser, psutil, protobuf, prompt-toolkit, prometheus-client, pkgutil_resolve_name, pip, Pillow, pbr, parso, pandocfilters, numpy, ntlm-auth, networkx, nest-asyncio, mypy-extensions, more-itertools, MarkupSafe, lxml, kiwisolver, joblib, jmespath, install, inflection, idna, grpcio, google-pasta, gast, docplex, dill, defusedxml, debugpy, cycler, charset-normalizer, certifi, backoff, Babel, attrs, async-generator, astor, absl-py, terminado, scipy, retworkx, requests, pydantic, pandas, packaging, opt-einsum, matplotlib, Keras-Preprocessing, jupyterlab-pygments, jupyter-core, Jinja2, jedi, importlib-resources, importlib-metadata, immutables, h5py, fastdtw, cffi, botocore, beautifulsoup4, anyio, yfinance, stevedore, scikit-learn, s3transfer, Quandl, Markdown, Keras-Applications, Keras, jupyter-client, jsonschema, ipython, cryptography, contextvars, bokeh, bleach, argon2-cffi-bindings, amazon-braket-schemas, tensorboard, requests-ntlm, qiskit-terra, openpulse, nbformat, ipykernel, boto3, argon2-cffi, amazon-braket-default-simulator, altair, tensorflow, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, oqpy, nbclient, qiskit-aqua, qiskit, nbconvert, amazon-braket-sdk, notebook, jupyter-server, notebook_shim, nbclassic, jupyterlab-server, jupyterlab\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.41.2\n",
      "    Uninstalling wheel-0.41.2:\n",
      "      Successfully uninstalled wheel-0.41.2\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.9.0\n",
      "    Uninstalling traitlets-5.9.0:\n",
      "      Successfully uninstalled traitlets-5.9.0\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.2\n",
      "    Uninstalling tornado-6.2:\n",
      "      Successfully uninstalled tornado-6.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 68.2.2\n",
      "    Uninstalling setuptools-68.2.2:\n",
      "      Successfully uninstalled setuptools-68.2.2\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 25.1.1\n",
      "    Uninstalling pyzmq-25.1.1:\n",
      "      Successfully uninstalled pyzmq-25.1.1\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.16.1\n",
      "    Uninstalling Pygments-2.16.1:\n",
      "      Successfully uninstalled Pygments-2.16.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.39\n",
      "    Uninstalling prompt-toolkit-3.0.39:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.39\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.3\n",
      "    Uninstalling parso-0.8.3:\n",
      "      Successfully uninstalled parso-0.8.3\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.8\n",
      "    Uninstalling nest-asyncio-1.5.8:\n",
      "      Successfully uninstalled nest-asyncio-1.5.8\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.7.0\n",
      "    Uninstalling debugpy-1.7.0:\n",
      "      Successfully uninstalled debugpy-1.7.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter_core 4.12.0\n",
      "    Uninstalling jupyter_core-4.12.0:\n",
      "      Successfully uninstalled jupyter_core-4.12.0\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.0\n",
      "    Uninstalling jedi-0.19.0:\n",
      "      Successfully uninstalled jedi-0.19.0\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter_client 7.4.9\n",
      "    Uninstalling jupyter_client-7.4.9:\n",
      "      Successfully uninstalled jupyter_client-7.4.9\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.34.0\n",
      "    Uninstalling ipython-7.34.0:\n",
      "      Successfully uninstalled ipython-7.34.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.16.2\n",
      "    Uninstalling ipykernel-6.16.2:\n",
      "      Successfully uninstalled ipykernel-6.16.2\n",
      "Successfully installed Babel-2.11.0 Jinja2-3.0.3 Keras-2.0.8 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.2 Markdown-3.3.7 MarkupSafe-2.0.1 Pillow-8.4.0 PyYAML-6.0 Pygments-2.14.0 Quandl-3.7.0 Send2Trash-1.8.0 Werkzeug-2.0.3 absl-py-1.4.0 altair-4.2.2 amazon-braket-default-simulator-1.11.5.post0 amazon-braket-schemas-1.14.1.post0 amazon-braket-sdk-1.35.5 antlr4-python3-runtime-4.9.2 anyio-3.6.2 appdirs-1.4.4 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 astor-0.8.1 async-generator-1.10 attrs-22.1.0 backoff-2.2.1 beautifulsoup4-4.11.2 bleach-4.1.0 bokeh-2.3.3 boltons-23.0.0 boto3-1.23.10 botocore-1.26.10 cached-property-1.5.2 certifi-2022.12.7 cffi-1.15.1 charset-normalizer-2.0.12 contextvars-2.4 cryptography-39.0.0 cycler-0.11.0 debugpy-1.6.6 defusedxml-0.7.1 dill-0.3.4 dlx-1.0.4 docplex-2.25.236 fastdtw-0.3.4 fastjsonschema-2.16.2 gast-0.2.2 google-pasta-0.2.0 grpcio-1.48.2 h5py-2.10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 importlib-resources-5.12.0 inflection-0.5.1 install-1.3.5 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 jmespath-0.10.0 joblib-1.1.1 json5-0.9.11 jsonschema-3.2.0 jupyter-client-7.1.2 jupyter-core-4.9.2 jupyter-server-1.13.1 jupyterlab-3.2.9 jupyterlab-pygments-0.1.2 jupyterlab-server-2.10.3 kiwisolver-1.3.1 lxml-4.9.2 matplotlib-3.3.4 mistune-0.8.4 more-itertools-8.14.0 mpmath-1.2.1 multitasking-0.0.11 mypy-extensions-1.0.0 nbclassic-0.3.5 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 nest-asyncio-1.5.6 networkx-2.6.3 notebook-6.4.10 notebook_shim-0.2.2 ntlm-auth-1.5.0 numpy-1.21.6 openpulse-0.4.1 openqasm3-0.4.0 opt-einsum-3.3.0 oqpy-0.1.2 packaging-21.3 pandas-1.1.5 pandocfilters-1.5.0 parso-0.7.1 pbr-5.11.1 pip-23.0.1 pkgutil_resolve_name-1.3.10 ply-3.11 prometheus-client-0.16.0 prompt-toolkit-3.0.36 protobuf-3.19.6 psutil-5.9.4 pyasn1-0.4.8 pycparser-2.21 pydantic-1.10.2 pyparsing-3.0.9 pyrsistent-0.18.0 python-constraint-1.4.0 pytz-2022.6 pyzmq-25.0.0 qiskit-0.34.2 qiskit-aer-0.10.3 qiskit-aqua-0.9.5 qiskit-ibmq-provider-0.18.3 qiskit-ignis-0.7.0 qiskit-terra-0.19.2 requests-2.27.1 requests-ntlm-1.1.0 retworkx-0.11.0 s3transfer-0.5.2 scikit-learn-0.24.2 scipy-1.5.4 setproctitle-1.3.2 setuptools-67.6.0 sniffio-1.2.0 soupsieve-2.4 stevedore-3.5.2 symengine-0.8.1 sympy-1.9 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-1.1.0 terminado-0.12.1 testpath-0.6.0 threadpoolctl-3.1.0 tinycss2-1.2.1 toolz-0.12.0 tornado-6.1 traitlets-4.3.3 tweedledum-1.1.1 typing_extensions-4.1.1 urllib3-1.26.14 webencodings-0.5.1 websocket-client-1.3.1 wheel-0.38.4 wrapt-1.14.1 yfinance-0.1.87 zipp-3.6.0\n",
      "rm: cannot remove ‘/home/ec2-user/.keras/keras.json’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!rm ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./hybridjobs/utility\")\n",
    "\n",
    "from hybridjobs.utility.ProteinParser import ProteinData\n",
    "from hybridjobs.utility.ProteinModel import ProteinModel\n",
    "from hybridjobs.utility.ProteinStructurePrediction import ProteinStructurePrediction\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we have prepared the precalculated energies files in advance for doing protein folding experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input: aminoacids\n",
    "# output: energy files\n",
    "\n",
    "protein_name = 'glycylglycine'\n",
    "aminoacids = 'GG'\n",
    "number_bits_to_discretize_protein_angles = 4\n",
    "protein_id = 0\n",
    "\n",
    "data_path='protein-folding-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Build Model\n",
    "\n",
    "In this part, we will show how to build model for qfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-qc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-qc\n"
     ]
    }
   ],
   "source": [
    "# initial the ProteinFold object\n",
    "init_param = {}\n",
    "# method: qfold-cc stands for the classical metropolis method in QFold\n",
    "# method: qfold-qc stands for the quantum metropolis method in QFold\n",
    "method = ['qfold-cc', 'qfold-qc']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'qfold-cc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "    elif mt == 'qfold-qc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "\n",
    "config_path = \"hybridjobs/config/config.json\"\n",
    "protein_model = ProteinModel(data_path, method, config_path, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameters for model\n",
    "model_param = {}\n",
    "\n",
    "method = 'qfold-cc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "method = 'qfold-qc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "protein_model.build_models(**model_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save protein_folding_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the protein folding models and saved them as protein_folding_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = protein_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the protein folding models and saved them as protein_folding_latest.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Predict Protein Structure\n",
    "\n",
    "In this part, we will show how to run models for predicting protein structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protein_models = ProteinModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:debug describe\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n"
     ]
    }
   ],
   "source": [
    "model_info = protein_models.describe_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "protein_name = 'glycylglycine_3_GG'\n",
    "initialization = 'random'\n",
    "method = 'qfold-cc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-cc in QFold\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 2 steps: 0.6116912364959717 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 3 steps: 0.6174771785736084 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 4 steps: 0.9570331573486328 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 5 steps: 1.0897619724273682 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 6 steps: 1.3576455116271973 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 7 steps: 1.714564323425293 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 8 steps: 1.8095722198486328 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 9 steps: 1.7752666473388672 seconds\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-cc.json\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# psp_param stands for the parameters for predicting protein structure\n",
    "psp_param = {}\n",
    "psp_param[\"data_path\"] = data_path\n",
    "psp_param[\"mode\"] = 'local-simulator'\n",
    "psp_param[\"model_name\"] = model_name\n",
    "psp_param[\"model_path\"] = model_path\n",
    "\n",
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initialization = 'random'\n",
    "method = 'qfold-qc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-qc in QFold\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.13137 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.10180 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.10800 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01025 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 28142.65633 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('cu3', 2), ('cx', 2), ('mcx', 4), ('mcx', 5), ('snapshot', 16), ('h', 1), ('ccx', 3), ('mcu1', 9), ('x', 1)} to target basis {'mcx', 'cu1', 'sx', 'h', 'mcsx', 'rzx', 'save_statevector', 'mcr', 'mcrz', 'reset', 'cp', 'sdg', 'u', 'initialize', 'cu', 'qerror_loc', 'p', 'swap', 'x', 'mcu', 'y', 'pauli', 'rz', 'kraus', 'id', 'quantum_channel', 'cy', 't', 'csx', 'rxx', 'cu3', 'rx', 'save_probs_ket', 'ccx', 'save_expval', 'save_amplitudes', 'mcswap', 'unitary', 'tdg', 'mcp', 'measure', 'diagonal', 'mcy', 'save_density_matrix', 'barrier', 'save_amplitudes_sq', 'mcu3', 'set_statevector', 'cu2', 'cswap', 'r', 'multiplexer', 'snapshot', 'delay', 'mcphase', 'u2', 'ry', 'rzz', 'mcz', 's', 'cx', 'cz', 'u3', 'u1', 'mcu2', 'z', 'roerror', 'mcrx', 'mcry', 'sxdg', 'ryy', 'save_probs', 'save_state', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.117s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.479s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 802.85501 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: RemoveResetInZeroState - 42.03534 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 46.63038 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01669 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 45115.16595 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 58.90751 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01144 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 85.12449 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('u3', 1), ('cu3', 2), ('cx', 2), ('u2', 1), ('h', 1), ('mcx', 5), ('mcx', 4), ('snapshot', 16), ('ccx', 3), ('mcu1', 9), ('x', 1)} to target basis {'mcx', 'cu1', 'sx', 'h', 'mcsx', 'rzx', 'save_statevector', 'mcr', 'mcrz', 'reset', 'cp', 'sdg', 'u', 'initialize', 'cu', 'qerror_loc', 'p', 'swap', 'x', 'mcu', 'y', 'pauli', 'rz', 'kraus', 'id', 'quantum_channel', 'cy', 't', 'csx', 'rxx', 'cu3', 'rx', 'save_probs_ket', 'ccx', 'save_expval', 'save_amplitudes', 'mcswap', 'unitary', 'tdg', 'mcp', 'measure', 'diagonal', 'mcy', 'save_density_matrix', 'barrier', 'save_amplitudes_sq', 'mcu3', 'set_statevector', 'cu2', 'cswap', 'r', 'multiplexer', 'snapshot', 'delay', 'mcphase', 'u2', 'ry', 'rzz', 'mcz', 's', 'cx', 'cz', 'u3', 'u1', 'mcu2', 'z', 'roerror', 'mcrx', 'mcry', 'sxdg', 'ryy', 'save_probs', 'save_state', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.048s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.243s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 364.99977 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 22.92442 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01407 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 8902.23336 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 58.91347 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01121 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 84.85293 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('u3', 1), ('cu3', 2), ('cx', 2), ('u2', 1), ('h', 1), ('mcx', 5), ('mcx', 4), ('snapshot', 16), ('ccx', 3), ('mcu1', 9), ('x', 1)} to target basis {'mcx', 'cu1', 'sx', 'h', 'mcsx', 'rzx', 'save_statevector', 'mcr', 'mcrz', 'reset', 'cp', 'sdg', 'u', 'initialize', 'cu', 'qerror_loc', 'p', 'swap', 'x', 'mcu', 'y', 'pauli', 'rz', 'kraus', 'id', 'quantum_channel', 'cy', 't', 'csx', 'rxx', 'cu3', 'rx', 'save_probs_ket', 'ccx', 'save_expval', 'save_amplitudes', 'mcswap', 'unitary', 'tdg', 'mcp', 'measure', 'diagonal', 'mcy', 'save_density_matrix', 'barrier', 'save_amplitudes_sq', 'mcu3', 'set_statevector', 'cu2', 'cswap', 'r', 'multiplexer', 'snapshot', 'delay', 'mcphase', 'u2', 'ry', 'rzz', 'mcz', 's', 'cx', 'cz', 'u3', 'u1', 'mcu2', 'z', 'roerror', 'mcrx', 'mcry', 'sxdg', 'ryy', 'save_probs', 'save_state', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.048s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.242s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 362.44583 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 22.56799 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01502 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 8889.43529 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 59.02743 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01097 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 84.81169 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('u3', 1), ('cu3', 2), ('cx', 2), ('u2', 1), ('h', 1), ('mcx', 5), ('mcx', 4), ('snapshot', 16), ('ccx', 3), ('mcu1', 9), ('x', 1)} to target basis {'mcx', 'cu1', 'sx', 'h', 'mcsx', 'rzx', 'save_statevector', 'mcr', 'mcrz', 'reset', 'cp', 'sdg', 'u', 'initialize', 'cu', 'qerror_loc', 'p', 'swap', 'x', 'mcu', 'y', 'pauli', 'rz', 'kraus', 'id', 'quantum_channel', 'cy', 't', 'csx', 'rxx', 'cu3', 'rx', 'save_probs_ket', 'ccx', 'save_expval', 'save_amplitudes', 'mcswap', 'unitary', 'tdg', 'mcp', 'measure', 'diagonal', 'mcy', 'save_density_matrix', 'barrier', 'save_amplitudes_sq', 'mcu3', 'set_statevector', 'cu2', 'cswap', 'r', 'multiplexer', 'snapshot', 'delay', 'mcphase', 'u2', 'ry', 'rzz', 'mcz', 's', 'cx', 'cz', 'u3', 'u1', 'mcu2', 'z', 'roerror', 'mcrx', 'mcry', 'sxdg', 'ryy', 'save_probs', 'save_state', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.047s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.243s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 362.15353 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: ContainsInstruction - 0.01287 (ms)\n",
      "INFO:qiskit.compiler.transpiler:Total Transpile Time - 96163.78665 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.15879 (ms)\n",
      "INFO:qiskit.execute_function:Total Job Submission Time - 376.99556 (ms)\n",
      "INFO:root:QUANTUM METROPOLIS: Time for final steps 102.30579781532288 seconds (98.40709066390991 seconds statevector)\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-qc.json\n"
     ]
    }
   ],
   "source": [
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min tts for classical method is 58.98483476110978, for quantum method is 125.83909728469\n"
     ]
    }
   ],
   "source": [
    "# The time for final steps can be compared among these two methods\n",
    "import json\n",
    "\n",
    "with open(\"tts_results_glycylglycine_3_GG+random_1000_qfold-cc.json\") as f:\n",
    "    qfold_cc_results = json.load(f)\n",
    "\n",
    "with open(\"tts_results_glycylglycine_3_GG+random_1000_qfold-qc.json\") as f:\n",
    "    qfold_qc_results = json.load(f)\n",
    "\n",
    "qfold_cc_min_tts = qfold_cc_results['final_stats']['min_tts']['value']\n",
    "qfold_qc_min_tts = qfold_qc_results['final_stats']['min_tts']['value']\n",
    "print(f\"The min tts for classical method is {qfold_cc_min_tts}, for quantum method is {qfold_qc_min_tts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.config import InstanceConfig\n",
    "from hybridjobs.utility.HybridJobHelpers import *\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare parameters for batch evaluation\n",
    "\n",
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"protein-folding-qrw\"\n",
    "data_path = 'protein-folding-data/precalculated_energies'\n",
    "suffix_check = [\"json\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"method\": [\"qfold-cc\", \"qfold-qc\"]},\n",
    "        {\"initialization\": [\"minifold\", \"random\"]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"mode\": [\"local-simulator\"]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"},{\"qc\": \"null\", \"cc\": \"ml.m5.4xlarge\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-qc-53d2cb00/protein-folding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path,suffix_check)\n",
    "print(f\"upload data to s3 path: {s3_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Prepare image for experiment\n",
    "\n",
    "In this part, we use the following code to prepare the image for experiment. For the first run, \n",
    "please run build_and_push.sh to create the image. For future experiments, avoid running\n",
    "build_and_push.sh unless you want to rebuild the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 685723555941 in region us-west-2: 685723555941.dkr.ecr.us-west-2.amazonaws.com/amazon-braket-protein-folding-qrw-jobs:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  102.7MB\n",
      "Step 1/4 : FROM 292282985366.dkr.ecr.us-west-2.amazonaws.com/amazon-braket-base-jobs:1.0-cpu-py37-ubuntu18.04\n",
      " ---> c2e3f19ae3b6\n",
      "Step 2/4 : RUN python3 -m pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> d0a4b1afada6\n",
      "Step 3/4 : RUN python3 -m pip install numpy==1.22     scipy==1.5.4     tensorflow==2.13.0     Keras==2.13.1     qiskit==0.34.2     qiskit-aer==0.10.3     qiskit-aqua==0.9.5     qiskit-ibmq-provider==0.18.3     qiskit-ignis==0.7.0     qiskit-terra==0.19.2     matplotlib==3.3.4     bokeh==2.3.3\n",
      " ---> Using cache\n",
      " ---> d1455da79ec0\n",
      "Step 4/4 : COPY hybridjobs/psi4 /home/ubuntu/psi4conda/bin/psi4\n",
      " ---> Using cache\n",
      " ---> c63562d9978b\n",
      "Successfully built c63562d9978b\n",
      "Successfully tagged amazon-braket-protein-folding-qrw-jobs:latest\n",
      "The push refers to repository [685723555941.dkr.ecr.us-west-2.amazonaws.com/amazon-braket-protein-folding-qrw-jobs]\n",
      "\n",
      "\u001b[1B3b845bd1: Preparing \n",
      "\u001b[1B70c82804: Preparing \n",
      "\u001b[1B0a8bc5e2: Preparing \n",
      "\u001b[1B580ea057: Preparing \n",
      "\u001b[1B3a6b6835: Preparing \n",
      "\u001b[1B1f92012d: Preparing \n",
      "\u001b[1B4bc6787c: Preparing \n",
      "\u001b[1B572e7076: Preparing \n",
      "\u001b[1B64251efe: Preparing \n",
      "\u001b[1B88da86f9: Preparing \n",
      "\u001b[1B9a869bbc: Preparing \n",
      "\u001b[1Becc136c2: Preparing \n",
      "\u001b[1B2433d532: Preparing \n",
      "\u001b[1B885e693b: Preparing \n",
      "\u001b[1Bdb401135: Preparing \n",
      "\u001b[1B41ecf1fc: Preparing \n",
      "\u001b[10B72e7076: Waiting g \n",
      "\u001b[12Bbc6787c: Waiting g \n",
      "\u001b[1B1bd012ab: Layer already exists \u001b[17A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2Klatest: digest: sha256:92d2538d7627b553b740048d1311aef9747ddd9a2222329731380518d2744d0c size: 4316\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name.lower()}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "# For the first run, please use the following code to create the image for this application. For future experiments, comment\n",
    "# the following code unless you want to rebuild the image\n",
    "!sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job info will be saved in protein-folding-qrw-hybrid-jobs.json\n"
     ]
    }
   ],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_jobs_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Launch Amazon Braket Hybrid Jobs for experiment\n",
    "\n",
    "In this part, we use the following code to launch the same number of hybrid jobs as the sets of parameters for this experiments.\n",
    "When the number of jobs exceeds 5 RPS, this thread will wait. The default setting of this experiment will take around **7 hours** to \n",
    "finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Long runnning cell due to Burst rate of CreateJob requests < 5 RPS\n",
    "# sudo apt-get install python-prctl at first\n",
    "# https://stackoverflow.com/questions/34361035/python-thread-name-doesnt-show-up-on-ps-or-htop\n",
    "from threading import Thread\n",
    "import threading\n",
    "import setproctitle\n",
    "\n",
    "def launch_hybrid_jobs(hybrid_job_params=hybrid_job_params, hybrid_jobs_json=hybrid_jobs_json):\n",
    "    setproctitle.setproctitle(threading.current_thread().name)\n",
    "    # parse evaluation parameters and trigger hybrid jobs:\n",
    "    jobs = []\n",
    "    names = []\n",
    "\n",
    "    job_name = f\"{experiment_name}-job\"\n",
    "    device_param_list = [\"shots\", \"device\"]\n",
    "\n",
    "    for job_param in hybrid_job_params:\n",
    "        \n",
    "        algorithm_param_name = \"\"\n",
    "        for k,v in job_param.items():\n",
    "            if k not in device_param_list:\n",
    "                algorithm_param_name = algorithm_param_name+f\"-{v[0]}\"\n",
    "        algorithm_param_name=algorithm_param_name[1:]\n",
    "        quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "        classical_device = job_param['device']['cc']\n",
    "\n",
    "        device_name = classical_device.replace(\".\",\"-\")\n",
    "        device_name = device_name.replace(\"x\",\"\")\n",
    "        \n",
    "        name = f\"{algorithm_param_name}-{device_name}-\" + str(int(time.time()))\n",
    "        name = name.lower()\n",
    "        # name = f\"{experiment_name}-\"+ str(int(time.time()))\n",
    "        print(f\"name is {name}\")\n",
    "\n",
    "        tmp_job = AwsQuantumJob.create(\n",
    "            device=quantum_device,\n",
    "            source_module=\"hybridjobs\",\n",
    "            entry_point=f\"hybridjobs.{job_name}:main\",\n",
    "            job_name=name,\n",
    "            hyperparameters=job_param,\n",
    "            input_data=s3_path,\n",
    "            instance_config=InstanceConfig(instanceType=classical_device),\n",
    "            image_uri=image_uri,\n",
    "            wait_until_complete=False,\n",
    "        )\n",
    "        \n",
    "#         from braket.jobs.local import LocalQuantumJob\n",
    "        \n",
    "#         tmp_job = LocalQuantumJob.create(\n",
    "#             device=quantum_device,\n",
    "#             source_module=f\"{experiment_name}\",\n",
    "#             entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "#             hyperparameters=job_param,\n",
    "#             input_data=s3_path,\n",
    "#             image_uri=image_uri,\n",
    "#         )   \n",
    "        \n",
    "        print(f\"Finish create {experiment_name} with {name}\")\n",
    "\n",
    "        jobs.append(tmp_job)\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "        while not queue_check(jobs):\n",
    "            time.sleep(5)\n",
    "    jobs_arn = []\n",
    "\n",
    "    for job in jobs:\n",
    "        jobs_arn.append(job.arn)\n",
    "\n",
    "    jobs_states = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"hybrid-jobs-arn\": jobs_arn,\n",
    "        \"names\": names\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # save hybrid job arn for further analysis\n",
    "    json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "    with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    print(f\"Finish launch all the hybrid jobs and save all the files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# remove existing hybrid_jobs_json file\n",
    "!rm {hybrid_jobs_json}\n",
    "\n",
    "t = Thread(target=launch_hybrid_jobs, name=\"launch-hybrid-job\", daemon=True).start()\n",
    "\n",
    "# launch_hybrid_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2-user  2452  0.0  0.0 119860  2728 pts/0    Ss+  05:49   0:00 /bin/bash -c ps -aux | grep launch-hybrid-job\n",
      "ec2-user  2454  0.0  0.0 119420   968 pts/0    S+   05:49   0:00 grep launch-hybrid-job\n",
      "ec2-user 32267  3.2  1.3 1701344 214332 ?      Ssl  05:46   0:04 launch-hybrid-job\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-large-1697176146\n",
      "Finish create protein-folding-qrw with q-m-l-ml-m5-large-1697176146\n",
      "There are 1 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-4large-1697176163\n",
      "Finish create protein-folding-qrw with q-m-l-ml-m5-4large-1697176163\n",
      "There are 2 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-large-1697176171\n",
      "Finish create protein-folding-qrw with q-r-l-ml-m5-large-1697176171\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-4large-1697176179\n",
      "Finish create protein-folding-qrw with q-r-l-ml-m5-4large-1697176179\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-large-1697176370\n",
      "Finish create protein-folding-qrw with q-m-l-ml-m5-large-1697176370\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-4large-1697176379\n",
      "Finish create protein-folding-qrw with q-m-l-ml-m5-4large-1697176379\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-large-1697176508\n",
      "Finish create protein-folding-qrw with q-r-l-ml-m5-large-1697176508\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-4large-1697176517\n",
      "Finish create protein-folding-qrw with q-r-l-ml-m5-4large-1697176517\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "Finish launch all the hybrid jobs and save all the files\n"
     ]
    }
   ],
   "source": [
    "# run the following scripts to check the created threads\n",
    "!ps -aux | grep launch-hybrid-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Jobs finish and visualize results\n",
    "\n",
    "Please use the following code to check the status of hybrid jobs. The status of hybrid jobs can also be checked in the Amazon Braket console. Optionally, if the email if input when deploying the solution, emails will be sent at the same number of hybrid jobs once \n",
    "the status of jobs changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-m-l-ml-m5-large-1696571643 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-4large-1696571658 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-large-1696571667 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-4large-1696571676 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-large-1696571866 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-4large-1696571875 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-large-1696572011 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-4large-1696572021 is : COMPLETED\n",
      "all jobs completed\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.large'}\", 'initialization': 'random', 'method': 'qfold-cc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [80.2793512683781, 82.84507059622045, 79.80480389291786, 73.90645184334613, 68.35430135379889, 61.21228579850771, 65.008484602282, 61.70899525614872], 'initialization_stats': {'phis_precision': [80.29186537993999], 'psis_precision': [12.524701960918216], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [0.9516641666115051], 'psis_initial_rotation': [0.8946429875990303]}, 'final_stats': {'min_tts': {'step': 7, 'value': 61.21228579850771}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.4xlarge'}\", 'initialization': 'minifold', 'method': 'qfold-qc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [297.20689904952036, 257.0768396884957, 341.8007711480159, 563.2642256428803, 491.2741292553694, 554.6665421562067, 339.5472618629955, 657.2258206536235], 'initialization_stats': {'phis_precision': [3.6561311085829273], 'psis_precision': [67.12967637818517], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [-1.4559184312820435], 'psis_initial_rotation': [2.6101088523864746]}, 'final_stats': {'min_tts': {'step': 3, 'value': 257.0768396884957}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.large'}\", 'initialization': 'minifold', 'method': 'qfold-cc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [157.86605269213337, 139.6835686703154, 123.70480259176448, 108.69841141590686, 91.24903646120212, 80.23226430980829, 77.8320584985468, 68.66988330790194], 'initialization_stats': {'phis_precision': [3.6561311085829273], 'psis_precision': [67.12967637818517], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [-1.4559184312820435], 'psis_initial_rotation': [2.6101088523864746]}, 'final_stats': {'min_tts': {'step': 9, 'value': 68.66988330790194}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.large'}\", 'initialization': 'random', 'method': 'qfold-qc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [125.83909728469, 162.79166953788086, 166.465828110322, 226.87516833617673, 262.532539034563, 315.34165138580204, 262.5463694025349, 225.99270849033556], 'initialization_stats': {'phis_precision': [80.29186537993999], 'psis_precision': [12.524701960918216], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [0.9516641666115051], 'psis_initial_rotation': [0.8946429875990303]}, 'final_stats': {'min_tts': {'step': 2, 'value': 125.83909728469}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.large'}\", 'initialization': 'minifold', 'method': 'qfold-qc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [297.20689904952036, 257.0768396884957, 341.8007711480159, 563.2642256428803, 491.2741292553694, 554.6665421562067, 339.5472618629955, 657.2258206536235], 'initialization_stats': {'phis_precision': [3.6561311085829273], 'psis_precision': [67.12967637818517], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [-1.4559184312820435], 'psis_initial_rotation': [2.6101088523864746]}, 'final_stats': {'min_tts': {'step': 3, 'value': 257.0768396884957}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.4xlarge'}\", 'initialization': 'random', 'method': 'qfold-cc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [96.18535585541932, 84.49594961357546, 73.35221375915637, 75.60493405528094, 72.15751902421889, 64.95541763502304, 61.73025519962184, 60.013306026093275], 'initialization_stats': {'phis_precision': [80.29186537993999], 'psis_precision': [12.524701960918216], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [0.9516641666115051], 'psis_initial_rotation': [0.8946429875990303]}, 'final_stats': {'min_tts': {'step': 9, 'value': 60.013306026093275}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.4xlarge'}\", 'initialization': 'random', 'method': 'qfold-qc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [125.83909728469, 162.79166953788086, 166.465828110322, 226.87516833617673, 262.532539034563, 315.34165138580204, 262.5463694025349, 225.99270849033556], 'initialization_stats': {'phis_precision': [80.29186537993999], 'psis_precision': [12.524701960918216], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [0.9516641666115051], 'psis_initial_rotation': [0.8946429875990303]}, 'final_stats': {'min_tts': {'step': 2, 'value': 125.83909728469}}}}}\n",
      "{'precalculated_energies': {'hypermeter': {'device': \"{'qc': 'null', 'cc': 'ml.m5.4xlarge'}\", 'initialization': 'minifold', 'method': 'qfold-cc', 'mode': 'local-simulator', 'shots': '10000'}, 'result': {'initial_step': 2, 'final_step': 10, 'tts': [129.26003378977657, 132.62954679704197, 122.37624671969553, 101.98467246242764, 93.76581670396135, 78.67322695123713, 71.63319207358597, 71.53747001172349], 'initialization_stats': {'phis_precision': [3.6561311085829273], 'psis_precision': [67.12967637818517], 'phi_angles_psi4': [1.5708134759948975], 'psi_angles_psi4': [-2.6404247826789864], 'phis_initial_rotation': [-1.4559184312820435], 'psis_initial_rotation': [2.6101088523864746]}, 'final_stats': {'min_tts': {'step': 9, 'value': 71.53747001172349}}}}}\n"
     ]
    }
   ],
   "source": [
    "# run the following code to test whether all the jobs finish\n",
    "results = []\n",
    "if os.path.exists(hybrid_jobs_json):\n",
    "    # recover hybrid jobs and show result\n",
    "    jobs_states_load = None\n",
    "    with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "        jobs_states_load = json.load(outfile)\n",
    "\n",
    "    completed_jobs_arn = set()\n",
    "\n",
    "    for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "        current_job = AwsQuantumJob(job_arn)\n",
    "        print(f\"the state of job {job_name} is : {current_job.state()}\")\n",
    "        if current_job.state() == 'COMPLETED':\n",
    "            completed_jobs_arn.update({job_arn})\n",
    "\n",
    "    whole_jobs_num = len(jobs_states_load[\"names\"])\n",
    "\n",
    "    if len(completed_jobs_arn) == whole_jobs_num:\n",
    "        print(f\"all jobs completed\")\n",
    "        for job_arn in completed_jobs_arn:\n",
    "            current_job = AwsQuantumJob(job_arn)\n",
    "            results.append(current_job.result())\n",
    "            print(current_job.result())\n",
    "        # display results\n",
    "        results = display_results(results, experiments_params)\n",
    "else:\n",
    "    print(f\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-57e126fbb67d4fc9b3eb73553a8a137d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-57e126fbb67d4fc9b3eb73553a8a137d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-57e126fbb67d4fc9b3eb73553a8a137d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-41dcebb3cd9891a21e8c911a7ca28d78\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Device\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Step\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Time to Solution\", \"type\": \"quantitative\"}}, \"height\": 600, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"protein-folding-qrw experiments\", \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-41dcebb3cd9891a21e8c911a7ca28d78\": [{\"Step\": 0, \"Time to Solution\": 80.2793512683781, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 1, \"Time to Solution\": 82.84507059622045, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 2, \"Time to Solution\": 79.80480389291786, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 3, \"Time to Solution\": 73.90645184334613, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 4, \"Time to Solution\": 68.35430135379889, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 5, \"Time to Solution\": 61.21228579850771, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 6, \"Time to Solution\": 65.008484602282, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 7, \"Time to Solution\": 61.70899525614872, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.large\"}, {\"Step\": 0, \"Time to Solution\": 297.20689904952036, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 1, \"Time to Solution\": 257.0768396884957, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 2, \"Time to Solution\": 341.8007711480159, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 3, \"Time to Solution\": 563.2642256428803, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 4, \"Time to Solution\": 491.2741292553694, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 5, \"Time to Solution\": 554.6665421562067, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 6, \"Time to Solution\": 339.5472618629955, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 7, \"Time to Solution\": 657.2258206536235, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 0, \"Time to Solution\": 157.86605269213337, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 1, \"Time to Solution\": 139.6835686703154, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 2, \"Time to Solution\": 123.70480259176448, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 3, \"Time to Solution\": 108.69841141590686, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 4, \"Time to Solution\": 91.24903646120212, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 5, \"Time to Solution\": 80.23226430980829, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 6, \"Time to Solution\": 77.8320584985468, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 7, \"Time to Solution\": 68.66988330790194, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 0, \"Time to Solution\": 125.83909728469, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 1, \"Time to Solution\": 162.79166953788086, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 2, \"Time to Solution\": 166.465828110322, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 3, \"Time to Solution\": 226.87516833617673, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 4, \"Time to Solution\": 262.532539034563, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 5, \"Time to Solution\": 315.34165138580204, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 6, \"Time to Solution\": 262.5463694025349, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 7, \"Time to Solution\": 225.99270849033556, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.large\"}, {\"Step\": 0, \"Time to Solution\": 297.20689904952036, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 1, \"Time to Solution\": 257.0768396884957, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 2, \"Time to Solution\": 341.8007711480159, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 3, \"Time to Solution\": 563.2642256428803, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 4, \"Time to Solution\": 491.2741292553694, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 5, \"Time to Solution\": 554.6665421562067, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 6, \"Time to Solution\": 339.5472618629955, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 7, \"Time to Solution\": 657.2258206536235, \"Device\": \"qfold-qc-minifold-local-simulator-ml.m5.large\"}, {\"Step\": 0, \"Time to Solution\": 96.18535585541932, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 1, \"Time to Solution\": 84.49594961357546, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 2, \"Time to Solution\": 73.35221375915637, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 3, \"Time to Solution\": 75.60493405528094, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 4, \"Time to Solution\": 72.15751902421889, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 5, \"Time to Solution\": 64.95541763502304, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 6, \"Time to Solution\": 61.73025519962184, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 7, \"Time to Solution\": 60.013306026093275, \"Device\": \"qfold-cc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 0, \"Time to Solution\": 125.83909728469, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 1, \"Time to Solution\": 162.79166953788086, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 2, \"Time to Solution\": 166.465828110322, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 3, \"Time to Solution\": 226.87516833617673, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 4, \"Time to Solution\": 262.532539034563, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 5, \"Time to Solution\": 315.34165138580204, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 6, \"Time to Solution\": 262.5463694025349, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 7, \"Time to Solution\": 225.99270849033556, \"Device\": \"qfold-qc-random-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 0, \"Time to Solution\": 129.26003378977657, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 1, \"Time to Solution\": 132.62954679704197, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 2, \"Time to Solution\": 122.37624671969553, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 3, \"Time to Solution\": 101.98467246242764, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 4, \"Time to Solution\": 93.76581670396135, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 5, \"Time to Solution\": 78.67322695123713, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 6, \"Time to Solution\": 71.63319207358597, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}, {\"Step\": 7, \"Time to Solution\": 71.53747001172349, \"Device\": \"qfold-cc-minifold-local-simulator-ml.m5.4xlarge\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_result = {}\n",
    "device_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,vs in results.items():\n",
    "    device_name = k\n",
    "    for index, v in enumerate(vs):\n",
    "        device_list.append(device_name)\n",
    "        x_list.append(index)\n",
    "        y_list.append(v)\n",
    "source = pd.DataFrame({\n",
    "    \"Step\": np.array(x_list),\n",
    "    \"Time to Solution\": np.array(y_list),\n",
    "    \"Device\": np.array(device_list),\n",
    "})\n",
    "\n",
    "alt.Chart(source).mark_line(point = True).encode(\n",
    "    x='Step',\n",
    "    y='Time to Solution',\n",
    "    color='Device',\n",
    ").properties(\n",
    "    title = f\"{experiment_name} experiments\",\n",
    "    width = 700,\n",
    "    height = 600,\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_qc_hcls_python37",
   "language": "python",
   "name": "conda_qc_hcls_python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
