{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0531faa8-9b68-4a7f-833a-b18efbac1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.config import InstanceConfig\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6283c75a-3c8b-4a9e-9fd8-709e7d8da56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "c = copy.deepcopy\n",
    "\n",
    "def get_key(single_dict):\n",
    "    for k in single_dict.keys():\n",
    "        return k\n",
    "\n",
    "def parse_params(params_list, hp, hp_list):\n",
    "    params = params_list[0]\n",
    "    k = get_key(params)\n",
    "    ps = params[k]\n",
    "    for p in ps:\n",
    "        hp[k] = p\n",
    "        if len(params_list) == 1:\n",
    "            hp_list.append(c(hp))\n",
    "        else:\n",
    "            parse_params(params_list[1:], hp, hp_list)\n",
    "\n",
    "def get_quantum_device(device_name):\n",
    "    device_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\"\n",
    "    try:\n",
    "        device = AwsDevice.get_devices(names=[device_name])\n",
    "        device_arn = device[0].arn\n",
    "    except Exception as e:\n",
    "        print(f\"fail to get {device_name}: {e}, use sv1 instead\")\n",
    "    return device_arn\n",
    "\n",
    "def upload_data(dir_name, aws_session=AwsSession()):\n",
    "    stream_s3_uri = aws_session.construct_s3_uri(aws_session.default_bucket(), dir_name)\n",
    "    return_path = None\n",
    "    \n",
    "    def _check_upload(file_name, check_list):\n",
    "        file_end = file_name.split('.')[-1]\n",
    "        if file_end in check_list:\n",
    "            path = f\"{stream_s3_uri}/\" + file_name.split('/')[-1]\n",
    "            aws_session.upload_to_s3(file_name, path)\n",
    "            \n",
    "    if os.path.isdir(dir_name):\n",
    "        dir_list = os.listdir(dir_name)\n",
    "        for file_name in dir_list:\n",
    "            _check_upload(os.path.join(dir_name,file_name), ['mol2'])\n",
    "        return_path = stream_s3_uri\n",
    "    else:\n",
    "        _check_upload(file_name, ['mol2'])\n",
    "        single_file_name = file_name.split('/')[-1]\n",
    "        return_path = f\"{stream_s3_uri}/{single_file_name}\"\n",
    "        \n",
    "    return return_path\n",
    "\n",
    "def queue_check(jobs):\n",
    "    queue_count = 0\n",
    "    running_count = 0\n",
    "    check_pass = True\n",
    "    for job in jobs:\n",
    "        # print(f\"job state {job.state()}\")\n",
    "        if job.state() == \"QUEUED\":\n",
    "            queue_count = queue_count + 1\n",
    "        if job.state() == \"RUNNING\":\n",
    "            running_count = running_count + 1\n",
    "        if queue_count == 4 or running_count == 4:\n",
    "            check_pass = False\n",
    "    \n",
    "    print(f\"queue_count {queue_count}, running_count {running_count}\")\n",
    "    \n",
    "    return check_pass\n",
    "\n",
    "def get_result(result):\n",
    "    return [result[\"hypermeter\"][\"D\"], result[\"hypermeter\"][\"M\"], int(result[\"hypermeter\"][\"D\"])*int(result[\"hypermeter\"][\"M\"]), result[\"time\"]]\n",
    "\n",
    "def display_results(results, experiments_params):\n",
    "    sorted_results = {}\n",
    "    for device in experiments_params[\"params\"][3][\"device\"]:\n",
    "        sorted_results[str(device)] = []\n",
    "    max_offset = 10\n",
    "    for result in results:\n",
    "        d = int(result[\"hypermeter\"][\"D\"])\n",
    "        m = int(result[\"hypermeter\"][\"M\"])\n",
    "        dm = (d * m)<<10 + d\n",
    "        device = result[\"hypermeter\"][\"device\"]\n",
    "        \n",
    "        if len(sorted_results[device]) == 0:\n",
    "            sorted_results[device].append(get_result(result))\n",
    "            continue\n",
    "        \n",
    "        last_idx = 0\n",
    "        for idx, sorted_result in enumerate(sorted_results[device]):\n",
    "            sorted_d = int(sorted_result[0])\n",
    "            sorted_m = int(sorted_result[1])\n",
    "            sorted_dm = (sorted_d * sorted_m)<<max_offset + sorted_d\n",
    "            \n",
    "            last_sorted_d = int(sorted_results[device][last_idx][0])\n",
    "            last_sorted_m = int(sorted_results[device][last_idx][1])\n",
    "            last_sorted_dm = (last_sorted_d * last_sorted_m)<<max_offset + last_sorted_d\n",
    "            \n",
    "            if last_sorted_dm < dm and dm < sorted_dm:\n",
    "                sorted_results[device].insert(idx,get_result(result))\n",
    "                break\n",
    "            elif dm < last_sorted_dm and idx == 0:\n",
    "                sorted_results[device].insert(last_idx,get_result(result))\n",
    "                break\n",
    "            elif dm > sorted_dm and idx == len(sorted_results[device])-1:\n",
    "                sorted_results[device].insert(idx+1,get_result(result))\n",
    "            \n",
    "            last_idx = idx\n",
    "    # print(f\"sorted result {sorted_results}\")\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2cc57f-b61f-48ef-8d7b-580f47f66d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'M': 1, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 1, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 2, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 2, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 3, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 3, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 4, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 4, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 5, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 5, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'M': 6, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'M': 6, 'D': 8, 'shots': 10000, 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"molecular-unfolding\"\n",
    "data_path = \"molecular-unfolding-data\"\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"M\": [1,2,3,4,5,6]},\n",
    "        {\"D\": [8]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"},{\"qc\": \"null\", \"cc\": \"ml.m5.4xlarge\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2062d7b-b958-4c35-bf9f-202480d4d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-us-east-1-002224604296/molecular-unfolding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path)\n",
    "print(f\"upload data to s3 path: {s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320b1c6b-c575-4d41-a69a-cde747d903cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 002224604296 in region us-east-1: 002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-molecular-unfolding-jobs:latest\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "# # Uncomment the following code if you want to rebuild the container\n",
    "# !sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c7a433-6518-4f13-8b0f-4abd35b4c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job info will be saved in molecular-unfolding-hybrid-jobs.json\n"
     ]
    }
   ],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_jobs_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d52f18-791a-4943-abaf-1a9911815709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long runnning cell due to Burst rate of CreateJob requests < 5 RPS\n",
    "# sudo apt-get install python-prctl at first\n",
    "# https://stackoverflow.com/questions/34361035/python-thread-name-doesnt-show-up-on-ps-or-htop\n",
    "from threading import Thread\n",
    "import threading\n",
    "import setproctitle\n",
    "\n",
    "def launch_hybrid_jobs(hybrid_job_params=hybrid_job_params, hybrid_jobs_json=hybrid_jobs_json):\n",
    "    setproctitle.setproctitle(threading.currentThread().name)\n",
    "    # parse evaluation parameters and trigger hybrid jobs:\n",
    "    jobs = []\n",
    "    names = []\n",
    "\n",
    "    job_name = f\"{experiment_name}-job\"\n",
    "\n",
    "    # from braket.jobs.local import LocalQuantumJob\n",
    "\n",
    "    for job_param in hybrid_job_params:\n",
    "        M = job_param['M']\n",
    "        D = job_param['D']\n",
    "        quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "        classical_device = job_param['device']['cc']\n",
    "\n",
    "        device_name = classical_device.replace(\".\",\"-\")\n",
    "        device_name = device_name.replace(\"x\",\"\")\n",
    "        \n",
    "        name = f\"{experiment_name}-M-{M}-D-{D}-{device_name}\" + str(int(time.time()))\n",
    "\n",
    "        tmp_job = AwsQuantumJob.create(\n",
    "            device=quantum_device,\n",
    "            source_module=f\"{experiment_name}\",\n",
    "            entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "            job_name=name,\n",
    "            hyperparameters=job_param,\n",
    "            input_data=s3_path,\n",
    "            instance_config=InstanceConfig(instanceType=classical_device),\n",
    "            image_uri=image_uri,\n",
    "            wait_until_complete=False,\n",
    "        )\n",
    "        \n",
    "        print(f\"Finish create {experiment_name} with M {M}, D {D} and device {device_name}\")\n",
    "\n",
    "        jobs.append(tmp_job)\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "        while not queue_check(jobs):\n",
    "            time.sleep(5)\n",
    "    jobs_arn = []\n",
    "\n",
    "    for job in jobs:\n",
    "        jobs_arn.append(job.arn)\n",
    "\n",
    "    jobs_states = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"hybrid-jobs-arn\": jobs_arn,\n",
    "        \"names\": names\n",
    "    }\n",
    "    \n",
    "    # save hybrid job arn for further analysis\n",
    "    json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "    with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    print(f\"Finish launch all the hybrid jobs and save all the files\")\n",
    "\n",
    "t = Thread(target=launch_hybrid_jobs, name=\"launch-hybrid-job\", daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216bd344-121f-4e2d-8b35-f64efd298567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu     85131  0.0  1.3 1667824 438060 ?      Ssl  Jan05   0:27 launch-hybrid-job\n",
      "ubuntu     90748  0.0  1.5 1864064 491840 ?      Ssl  Jan06   1:40 launch-hybrid-job\n",
      "ubuntu    138118 11.8  1.2 1650156 385820 ?      Ssl  02:34   0:04 launch-hybrid-job\n",
      "ubuntu    138157  0.0  0.0   8748  3284 pts/1    Ss+  02:35   0:00 /bin/bash -c ps -aux | grep launch-hybrid-job\n",
      "ubuntu    138159  0.0  0.0   8176   660 pts/1    S+   02:35   0:00 grep launch-hybrid-job\n",
      "Finish create molecular-unfolding with M 3, D 8 and device ml-m5-large\n",
      "queue_count 1, running_count 4\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 5\n",
      "queue_count 0, running_count 4\n",
      "queue_count 0, running_count 1\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 3, D 8 and device ml-m5-4large\n",
      "queue_count 1, running_count 1\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 4, D 8 and device ml-m5-large\n",
      "queue_count 0, running_count 3\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "Finish create molecular-unfolding with M 4, D 8 and device ml-m5-4large\n",
      "queue_count 0, running_count 4\n"
     ]
    }
   ],
   "source": [
    "# run the following scripts to check the created threads\n",
    "!ps -aux | grep launch-hybrid-job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a643773a-ecaa-4af5-a7eb-ed276f7930b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\n"
     ]
    }
   ],
   "source": [
    "# run the following code to test whether all the jobs finish\n",
    "results = []\n",
    "if os.path.exists(hybrid_jobs_json):\n",
    "    # recover hybrid jobs and show result\n",
    "    jobs_states_load = None\n",
    "    with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "        jobs_states_load = json.load(outfile)\n",
    "\n",
    "    completed_jobs_arn = set()\n",
    "\n",
    "    for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "        current_job = AwsQuantumJob(job_arn)\n",
    "        print(f\"the state of job {job_name} is : {current_job.state()}\")\n",
    "        if current_job.state() == 'COMPLETED':\n",
    "            completed_jobs_arn.update({job_arn})\n",
    "\n",
    "    whole_jobs_num = len(jobs_states_load[\"names\"])\n",
    "\n",
    "    results = None\n",
    "    if len(completed_jobs_arn) == whole_jobs_num:\n",
    "        print(f\"all jobs completed\")\n",
    "        results = []\n",
    "        for job_arn in completed_jobs_arn:\n",
    "            current_job = AwsQuantumJob(job_arn)\n",
    "            results.append(current_job.result())\n",
    "        # display results\n",
    "        results = display_results(results, experiments_params)\n",
    "else:\n",
    "    print(f\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9924cb0d-be27-49be-a8f0-e466648e269a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m x_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m y_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,vs \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      6\u001b[0m     k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     dict_k \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(k)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "rename_result = {}\n",
    "device_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,vs in results.items():\n",
    "    k = k.replace(\"\\'\",\"\\\"\")\n",
    "    dict_k = json.loads(k)\n",
    "    device_name = None\n",
    "    if dict_k['qc'] == 'null':\n",
    "        device_name = dict_k['cc']\n",
    "    else:\n",
    "        device_name = dict_k['qc']\n",
    "    for v in vs:\n",
    "        device_list.append(device_name)\n",
    "        x_list.append(v[2])\n",
    "        y_list.append(v[3])\n",
    "source = pd.DataFrame({\n",
    "    \"DxM\": np.array(x_list),\n",
    "    \"Time to Solution\": np.array(y_list),\n",
    "    \"Device\": np.array(device_list),\n",
    "})\n",
    "\n",
    "alt.Chart(source).mark_line(point = True).encode(\n",
    "    x='DxM',\n",
    "    y='Time to Solution',\n",
    "    color='Device',\n",
    ").properties(\n",
    "    title = \"Molecular unfolding experiments\",\n",
    "    width = 700,\n",
    "    height = 600,\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
